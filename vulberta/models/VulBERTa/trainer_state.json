{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.090709567664633,
  "global_step": 580000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 4.997374694151869e-05,
      "loss": 7.1789,
      "step": 500
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.994749388303738e-05,
      "loss": 6.6683,
      "step": 1000
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.992124082455606e-05,
      "loss": 6.538,
      "step": 1500
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.989498776607475e-05,
      "loss": 6.4304,
      "step": 2000
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.986873470759344e-05,
      "loss": 6.3354,
      "step": 2500
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.984248164911212e-05,
      "loss": 6.2577,
      "step": 3000
    },
    {
      "epoch": 0.04,
      "learning_rate": 4.981622859063081e-05,
      "loss": 6.1851,
      "step": 3500
    },
    {
      "epoch": 0.04,
      "learning_rate": 4.9789975532149494e-05,
      "loss": 6.1145,
      "step": 4000
    },
    {
      "epoch": 0.05,
      "learning_rate": 4.976372247366818e-05,
      "loss": 6.0669,
      "step": 4500
    },
    {
      "epoch": 0.05,
      "learning_rate": 4.973746941518687e-05,
      "loss": 5.9964,
      "step": 5000
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.971121635670556e-05,
      "loss": 5.9181,
      "step": 5500
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.968496329822425e-05,
      "loss": 5.8362,
      "step": 6000
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.965871023974293e-05,
      "loss": 5.7382,
      "step": 6500
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.963245718126162e-05,
      "loss": 5.6199,
      "step": 7000
    },
    {
      "epoch": 0.08,
      "learning_rate": 4.960620412278031e-05,
      "loss": 5.4467,
      "step": 7500
    },
    {
      "epoch": 0.08,
      "learning_rate": 4.957995106429899e-05,
      "loss": 5.2669,
      "step": 8000
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.955369800581768e-05,
      "loss": 5.0831,
      "step": 8500
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.952744494733636e-05,
      "loss": 4.8109,
      "step": 9000
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.950119188885505e-05,
      "loss": 4.5817,
      "step": 9500
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.947493883037374e-05,
      "loss": 4.2552,
      "step": 10000
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.944868577189243e-05,
      "loss": 3.9442,
      "step": 10500
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.942243271341112e-05,
      "loss": 3.6942,
      "step": 11000
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.93961796549298e-05,
      "loss": 3.4781,
      "step": 11500
    },
    {
      "epoch": 0.13,
      "learning_rate": 4.936992659644849e-05,
      "loss": 3.3099,
      "step": 12000
    },
    {
      "epoch": 0.13,
      "learning_rate": 4.934367353796718e-05,
      "loss": 3.1628,
      "step": 12500
    },
    {
      "epoch": 0.14,
      "learning_rate": 4.931742047948587e-05,
      "loss": 3.0525,
      "step": 13000
    },
    {
      "epoch": 0.14,
      "learning_rate": 4.929116742100455e-05,
      "loss": 2.9641,
      "step": 13500
    },
    {
      "epoch": 0.15,
      "learning_rate": 4.926491436252323e-05,
      "loss": 2.8442,
      "step": 14000
    },
    {
      "epoch": 0.15,
      "learning_rate": 4.923866130404192e-05,
      "loss": 2.7509,
      "step": 14500
    },
    {
      "epoch": 0.16,
      "learning_rate": 4.921240824556061e-05,
      "loss": 2.6783,
      "step": 15000
    },
    {
      "epoch": 0.16,
      "learning_rate": 4.91861551870793e-05,
      "loss": 2.6383,
      "step": 15500
    },
    {
      "epoch": 0.17,
      "learning_rate": 4.915990212859799e-05,
      "loss": 2.5581,
      "step": 16000
    },
    {
      "epoch": 0.17,
      "learning_rate": 4.913364907011667e-05,
      "loss": 2.521,
      "step": 16500
    },
    {
      "epoch": 0.18,
      "learning_rate": 4.910739601163536e-05,
      "loss": 2.4423,
      "step": 17000
    },
    {
      "epoch": 0.18,
      "learning_rate": 4.908114295315405e-05,
      "loss": 2.408,
      "step": 17500
    },
    {
      "epoch": 0.19,
      "learning_rate": 4.905488989467274e-05,
      "loss": 2.3529,
      "step": 18000
    },
    {
      "epoch": 0.19,
      "learning_rate": 4.902863683619142e-05,
      "loss": 2.3082,
      "step": 18500
    },
    {
      "epoch": 0.2,
      "learning_rate": 4.90023837777101e-05,
      "loss": 2.2894,
      "step": 19000
    },
    {
      "epoch": 0.2,
      "learning_rate": 4.897613071922879e-05,
      "loss": 2.2647,
      "step": 19500
    },
    {
      "epoch": 0.21,
      "learning_rate": 4.894987766074748e-05,
      "loss": 2.1997,
      "step": 20000
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.892362460226617e-05,
      "loss": 2.1634,
      "step": 20500
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.889737154378486e-05,
      "loss": 2.1426,
      "step": 21000
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.887111848530354e-05,
      "loss": 2.121,
      "step": 21500
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.884486542682223e-05,
      "loss": 2.0834,
      "step": 22000
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.881861236834092e-05,
      "loss": 2.0549,
      "step": 22500
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.8792359309859606e-05,
      "loss": 2.0405,
      "step": 23000
    },
    {
      "epoch": 0.25,
      "learning_rate": 4.876610625137829e-05,
      "loss": 2.0133,
      "step": 23500
    },
    {
      "epoch": 0.25,
      "learning_rate": 4.873985319289697e-05,
      "loss": 1.9807,
      "step": 24000
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.871360013441566e-05,
      "loss": 1.9775,
      "step": 24500
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.868734707593435e-05,
      "loss": 1.9456,
      "step": 25000
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.866109401745304e-05,
      "loss": 1.9341,
      "step": 25500
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.863484095897172e-05,
      "loss": 1.9079,
      "step": 26000
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.860858790049041e-05,
      "loss": 1.878,
      "step": 26500
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.85823348420091e-05,
      "loss": 1.862,
      "step": 27000
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.8556081783527786e-05,
      "loss": 1.8434,
      "step": 27500
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.8529828725046475e-05,
      "loss": 1.8322,
      "step": 28000
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.850357566656516e-05,
      "loss": 1.814,
      "step": 28500
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.847732260808384e-05,
      "loss": 1.7932,
      "step": 29000
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.845106954960253e-05,
      "loss": 1.7774,
      "step": 29500
    },
    {
      "epoch": 0.32,
      "learning_rate": 4.842481649112122e-05,
      "loss": 1.757,
      "step": 30000
    },
    {
      "epoch": 0.32,
      "learning_rate": 4.8398563432639906e-05,
      "loss": 1.7481,
      "step": 30500
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.837231037415859e-05,
      "loss": 1.7363,
      "step": 31000
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.834605731567728e-05,
      "loss": 1.727,
      "step": 31500
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.8319804257195966e-05,
      "loss": 1.7032,
      "step": 32000
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.8293551198714655e-05,
      "loss": 1.6754,
      "step": 32500
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.8267298140233344e-05,
      "loss": 1.6672,
      "step": 33000
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.8241045081752026e-05,
      "loss": 1.6641,
      "step": 33500
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.821479202327071e-05,
      "loss": 1.6477,
      "step": 34000
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.81885389647894e-05,
      "loss": 1.6272,
      "step": 34500
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.8162285906308086e-05,
      "loss": 1.6419,
      "step": 35000
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.8136032847826775e-05,
      "loss": 1.6085,
      "step": 35500
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.810977978934546e-05,
      "loss": 1.6157,
      "step": 36000
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.8083526730864146e-05,
      "loss": 1.602,
      "step": 36500
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.8057273672382835e-05,
      "loss": 1.5878,
      "step": 37000
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.8031020613901524e-05,
      "loss": 1.5691,
      "step": 37500
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.800476755542021e-05,
      "loss": 1.5629,
      "step": 38000
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.7978514496938895e-05,
      "loss": 1.5531,
      "step": 38500
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.7952261438457584e-05,
      "loss": 1.5485,
      "step": 39000
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.7926008379976266e-05,
      "loss": 1.5296,
      "step": 39500
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.7899755321494955e-05,
      "loss": 1.527,
      "step": 40000
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.7873502263013644e-05,
      "loss": 1.5191,
      "step": 40500
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.7847249204532326e-05,
      "loss": 1.5065,
      "step": 41000
    },
    {
      "epoch": 0.44,
      "learning_rate": 4.7820996146051015e-05,
      "loss": 1.5002,
      "step": 41500
    },
    {
      "epoch": 0.44,
      "learning_rate": 4.7794743087569704e-05,
      "loss": 1.5093,
      "step": 42000
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.776849002908839e-05,
      "loss": 1.5014,
      "step": 42500
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.774223697060708e-05,
      "loss": 1.4855,
      "step": 43000
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.7715983912125764e-05,
      "loss": 1.4789,
      "step": 43500
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.768973085364445e-05,
      "loss": 1.482,
      "step": 44000
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.7663477795163135e-05,
      "loss": 1.46,
      "step": 44500
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.7637224736681824e-05,
      "loss": 1.4604,
      "step": 45000
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.761097167820051e-05,
      "loss": 1.4397,
      "step": 45500
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.7584718619719196e-05,
      "loss": 1.444,
      "step": 46000
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.7558465561237884e-05,
      "loss": 1.4325,
      "step": 46500
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.7532212502756573e-05,
      "loss": 1.4281,
      "step": 47000
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.750595944427526e-05,
      "loss": 1.4192,
      "step": 47500
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.747970638579395e-05,
      "loss": 1.417,
      "step": 48000
    },
    {
      "epoch": 0.51,
      "learning_rate": 4.7453453327312633e-05,
      "loss": 1.4097,
      "step": 48500
    },
    {
      "epoch": 0.51,
      "learning_rate": 4.742720026883132e-05,
      "loss": 1.396,
      "step": 49000
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.740094721035001e-05,
      "loss": 1.3989,
      "step": 49500
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.7374694151868694e-05,
      "loss": 1.3839,
      "step": 50000
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.734844109338738e-05,
      "loss": 1.3975,
      "step": 50500
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.7322188034906065e-05,
      "loss": 1.3727,
      "step": 51000
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.7295934976424754e-05,
      "loss": 1.3738,
      "step": 51500
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.726968191794344e-05,
      "loss": 1.3641,
      "step": 52000
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.724342885946213e-05,
      "loss": 1.3606,
      "step": 52500
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.721717580098082e-05,
      "loss": 1.3465,
      "step": 53000
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.71909227424995e-05,
      "loss": 1.3455,
      "step": 53500
    },
    {
      "epoch": 0.57,
      "learning_rate": 4.716466968401819e-05,
      "loss": 1.3436,
      "step": 54000
    },
    {
      "epoch": 0.57,
      "learning_rate": 4.713841662553688e-05,
      "loss": 1.3411,
      "step": 54500
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.711216356705556e-05,
      "loss": 1.3347,
      "step": 55000
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.708591050857425e-05,
      "loss": 1.3324,
      "step": 55500
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.7059657450092934e-05,
      "loss": 1.3406,
      "step": 56000
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.703340439161162e-05,
      "loss": 1.3123,
      "step": 56500
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.700715133313031e-05,
      "loss": 1.3251,
      "step": 57000
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.6980898274649e-05,
      "loss": 1.3217,
      "step": 57500
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.695464521616769e-05,
      "loss": 1.3193,
      "step": 58000
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.692839215768637e-05,
      "loss": 1.3028,
      "step": 58500
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.690213909920506e-05,
      "loss": 1.2932,
      "step": 59000
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.687588604072375e-05,
      "loss": 1.2955,
      "step": 59500
    },
    {
      "epoch": 0.63,
      "learning_rate": 4.684963298224244e-05,
      "loss": 1.2878,
      "step": 60000
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.682337992376112e-05,
      "loss": 1.2807,
      "step": 60500
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.67971268652798e-05,
      "loss": 1.2842,
      "step": 61000
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.677087380679849e-05,
      "loss": 1.2764,
      "step": 61500
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.674462074831718e-05,
      "loss": 1.2701,
      "step": 62000
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.671836768983587e-05,
      "loss": 1.2666,
      "step": 62500
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.669211463135456e-05,
      "loss": 1.2703,
      "step": 63000
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.666586157287324e-05,
      "loss": 1.2564,
      "step": 63500
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.663960851439193e-05,
      "loss": 1.2639,
      "step": 64000
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.661335545591062e-05,
      "loss": 1.2486,
      "step": 64500
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.658710239742931e-05,
      "loss": 1.2448,
      "step": 65000
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.656084933894799e-05,
      "loss": 1.2517,
      "step": 65500
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.653459628046667e-05,
      "loss": 1.2534,
      "step": 66000
    },
    {
      "epoch": 0.7,
      "learning_rate": 4.650834322198536e-05,
      "loss": 1.2359,
      "step": 66500
    },
    {
      "epoch": 0.7,
      "learning_rate": 4.648209016350405e-05,
      "loss": 1.2301,
      "step": 67000
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.645583710502274e-05,
      "loss": 1.2324,
      "step": 67500
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.642958404654143e-05,
      "loss": 1.2261,
      "step": 68000
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.640333098806011e-05,
      "loss": 1.2321,
      "step": 68500
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.63770779295788e-05,
      "loss": 1.2075,
      "step": 69000
    },
    {
      "epoch": 0.73,
      "learning_rate": 4.635082487109749e-05,
      "loss": 1.2173,
      "step": 69500
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.632457181261618e-05,
      "loss": 1.2171,
      "step": 70000
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.629831875413486e-05,
      "loss": 1.2171,
      "step": 70500
    },
    {
      "epoch": 0.75,
      "learning_rate": 4.627206569565354e-05,
      "loss": 1.2128,
      "step": 71000
    },
    {
      "epoch": 0.75,
      "learning_rate": 4.624581263717223e-05,
      "loss": 1.2037,
      "step": 71500
    },
    {
      "epoch": 0.76,
      "learning_rate": 4.621955957869092e-05,
      "loss": 1.2014,
      "step": 72000
    },
    {
      "epoch": 0.76,
      "learning_rate": 4.619330652020961e-05,
      "loss": 1.2122,
      "step": 72500
    },
    {
      "epoch": 0.77,
      "learning_rate": 4.61670534617283e-05,
      "loss": 1.1955,
      "step": 73000
    },
    {
      "epoch": 0.77,
      "learning_rate": 4.614080040324698e-05,
      "loss": 1.1883,
      "step": 73500
    },
    {
      "epoch": 0.78,
      "learning_rate": 4.611454734476567e-05,
      "loss": 1.1962,
      "step": 74000
    },
    {
      "epoch": 0.78,
      "learning_rate": 4.608829428628436e-05,
      "loss": 1.1951,
      "step": 74500
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.6062041227803046e-05,
      "loss": 1.1829,
      "step": 75000
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.603578816932173e-05,
      "loss": 1.1815,
      "step": 75500
    },
    {
      "epoch": 0.8,
      "learning_rate": 4.600953511084041e-05,
      "loss": 1.1829,
      "step": 76000
    },
    {
      "epoch": 0.8,
      "learning_rate": 4.59832820523591e-05,
      "loss": 1.1728,
      "step": 76500
    },
    {
      "epoch": 0.81,
      "learning_rate": 4.595702899387779e-05,
      "loss": 1.1947,
      "step": 77000
    },
    {
      "epoch": 0.81,
      "learning_rate": 4.593077593539648e-05,
      "loss": 1.1754,
      "step": 77500
    },
    {
      "epoch": 0.82,
      "learning_rate": 4.590452287691516e-05,
      "loss": 1.1637,
      "step": 78000
    },
    {
      "epoch": 0.82,
      "learning_rate": 4.587826981843385e-05,
      "loss": 1.155,
      "step": 78500
    },
    {
      "epoch": 0.83,
      "learning_rate": 4.585201675995254e-05,
      "loss": 1.1644,
      "step": 79000
    },
    {
      "epoch": 0.83,
      "learning_rate": 4.5825763701471226e-05,
      "loss": 1.1557,
      "step": 79500
    },
    {
      "epoch": 0.84,
      "learning_rate": 4.5799510642989915e-05,
      "loss": 1.1487,
      "step": 80000
    },
    {
      "epoch": 0.85,
      "learning_rate": 4.57732575845086e-05,
      "loss": 1.1576,
      "step": 80500
    },
    {
      "epoch": 0.85,
      "learning_rate": 4.574700452602728e-05,
      "loss": 1.1558,
      "step": 81000
    },
    {
      "epoch": 0.86,
      "learning_rate": 4.572075146754597e-05,
      "loss": 1.1431,
      "step": 81500
    },
    {
      "epoch": 0.86,
      "learning_rate": 4.569449840906466e-05,
      "loss": 1.1469,
      "step": 82000
    },
    {
      "epoch": 0.87,
      "learning_rate": 4.5668245350583346e-05,
      "loss": 1.1427,
      "step": 82500
    },
    {
      "epoch": 0.87,
      "learning_rate": 4.564199229210203e-05,
      "loss": 1.1307,
      "step": 83000
    },
    {
      "epoch": 0.88,
      "learning_rate": 4.561573923362072e-05,
      "loss": 1.1274,
      "step": 83500
    },
    {
      "epoch": 0.88,
      "learning_rate": 4.5589486175139406e-05,
      "loss": 1.1242,
      "step": 84000
    },
    {
      "epoch": 0.89,
      "learning_rate": 4.5563233116658095e-05,
      "loss": 1.1379,
      "step": 84500
    },
    {
      "epoch": 0.89,
      "learning_rate": 4.5536980058176784e-05,
      "loss": 1.1226,
      "step": 85000
    },
    {
      "epoch": 0.9,
      "learning_rate": 4.5510726999695466e-05,
      "loss": 1.1257,
      "step": 85500
    },
    {
      "epoch": 0.9,
      "learning_rate": 4.5484473941214155e-05,
      "loss": 1.1282,
      "step": 86000
    },
    {
      "epoch": 0.91,
      "learning_rate": 4.545822088273284e-05,
      "loss": 1.1232,
      "step": 86500
    },
    {
      "epoch": 0.91,
      "learning_rate": 4.5431967824251526e-05,
      "loss": 1.1174,
      "step": 87000
    },
    {
      "epoch": 0.92,
      "learning_rate": 4.5405714765770215e-05,
      "loss": 1.1217,
      "step": 87500
    },
    {
      "epoch": 0.92,
      "learning_rate": 4.53794617072889e-05,
      "loss": 1.1123,
      "step": 88000
    },
    {
      "epoch": 0.93,
      "learning_rate": 4.5353208648807586e-05,
      "loss": 1.1032,
      "step": 88500
    },
    {
      "epoch": 0.93,
      "learning_rate": 4.5326955590326275e-05,
      "loss": 1.1127,
      "step": 89000
    },
    {
      "epoch": 0.94,
      "learning_rate": 4.5300702531844964e-05,
      "loss": 1.1023,
      "step": 89500
    },
    {
      "epoch": 0.95,
      "learning_rate": 4.527444947336365e-05,
      "loss": 1.0997,
      "step": 90000
    },
    {
      "epoch": 0.95,
      "learning_rate": 4.5248196414882335e-05,
      "loss": 1.1069,
      "step": 90500
    },
    {
      "epoch": 0.96,
      "learning_rate": 4.5221943356401024e-05,
      "loss": 1.1055,
      "step": 91000
    },
    {
      "epoch": 0.96,
      "learning_rate": 4.5195690297919706e-05,
      "loss": 1.0982,
      "step": 91500
    },
    {
      "epoch": 0.97,
      "learning_rate": 4.5169437239438395e-05,
      "loss": 1.1003,
      "step": 92000
    },
    {
      "epoch": 0.97,
      "learning_rate": 4.5143184180957084e-05,
      "loss": 1.0972,
      "step": 92500
    },
    {
      "epoch": 0.98,
      "learning_rate": 4.5116931122475767e-05,
      "loss": 1.0911,
      "step": 93000
    },
    {
      "epoch": 0.98,
      "learning_rate": 4.5090678063994455e-05,
      "loss": 1.082,
      "step": 93500
    },
    {
      "epoch": 0.99,
      "learning_rate": 4.5064425005513144e-05,
      "loss": 1.0943,
      "step": 94000
    },
    {
      "epoch": 0.99,
      "learning_rate": 4.503817194703183e-05,
      "loss": 1.083,
      "step": 94500
    },
    {
      "epoch": 1.0,
      "learning_rate": 4.501191888855052e-05,
      "loss": 1.0828,
      "step": 95000
    },
    {
      "epoch": 1.0,
      "learning_rate": 4.4985665830069204e-05,
      "loss": 1.0826,
      "step": 95500
    },
    {
      "epoch": 1.01,
      "learning_rate": 4.4959412771587893e-05,
      "loss": 1.0585,
      "step": 96000
    },
    {
      "epoch": 1.01,
      "learning_rate": 4.493315971310658e-05,
      "loss": 1.0724,
      "step": 96500
    },
    {
      "epoch": 1.02,
      "learning_rate": 4.4906906654625265e-05,
      "loss": 1.0659,
      "step": 97000
    },
    {
      "epoch": 1.02,
      "learning_rate": 4.4880653596143953e-05,
      "loss": 1.0724,
      "step": 97500
    },
    {
      "epoch": 1.03,
      "learning_rate": 4.4854400537662636e-05,
      "loss": 1.0575,
      "step": 98000
    },
    {
      "epoch": 1.03,
      "learning_rate": 4.4828147479181325e-05,
      "loss": 1.0646,
      "step": 98500
    },
    {
      "epoch": 1.04,
      "learning_rate": 4.4801894420700014e-05,
      "loss": 1.0523,
      "step": 99000
    },
    {
      "epoch": 1.04,
      "learning_rate": 4.47756413622187e-05,
      "loss": 1.0568,
      "step": 99500
    },
    {
      "epoch": 1.05,
      "learning_rate": 4.474938830373739e-05,
      "loss": 1.0663,
      "step": 100000
    },
    {
      "epoch": 1.06,
      "learning_rate": 4.4723135245256074e-05,
      "loss": 1.0575,
      "step": 100500
    },
    {
      "epoch": 1.06,
      "learning_rate": 4.469688218677476e-05,
      "loss": 1.0504,
      "step": 101000
    },
    {
      "epoch": 1.07,
      "learning_rate": 4.467062912829345e-05,
      "loss": 1.0567,
      "step": 101500
    },
    {
      "epoch": 1.07,
      "learning_rate": 4.4644376069812134e-05,
      "loss": 1.0455,
      "step": 102000
    },
    {
      "epoch": 1.08,
      "learning_rate": 4.461812301133082e-05,
      "loss": 1.0462,
      "step": 102500
    },
    {
      "epoch": 1.08,
      "learning_rate": 4.4591869952849505e-05,
      "loss": 1.0353,
      "step": 103000
    },
    {
      "epoch": 1.09,
      "learning_rate": 4.4565616894368194e-05,
      "loss": 1.0291,
      "step": 103500
    },
    {
      "epoch": 1.09,
      "learning_rate": 4.453936383588688e-05,
      "loss": 1.0425,
      "step": 104000
    },
    {
      "epoch": 1.1,
      "learning_rate": 4.451311077740557e-05,
      "loss": 1.0449,
      "step": 104500
    },
    {
      "epoch": 1.1,
      "learning_rate": 4.448685771892426e-05,
      "loss": 1.0336,
      "step": 105000
    },
    {
      "epoch": 1.11,
      "learning_rate": 4.446060466044294e-05,
      "loss": 1.0315,
      "step": 105500
    },
    {
      "epoch": 1.11,
      "learning_rate": 4.443435160196163e-05,
      "loss": 1.0417,
      "step": 106000
    },
    {
      "epoch": 1.12,
      "learning_rate": 4.440809854348032e-05,
      "loss": 1.033,
      "step": 106500
    },
    {
      "epoch": 1.12,
      "learning_rate": 4.4381845484999e-05,
      "loss": 1.0229,
      "step": 107000
    },
    {
      "epoch": 1.13,
      "learning_rate": 4.435559242651769e-05,
      "loss": 1.027,
      "step": 107500
    },
    {
      "epoch": 1.13,
      "learning_rate": 4.4329339368036374e-05,
      "loss": 1.0203,
      "step": 108000
    },
    {
      "epoch": 1.14,
      "learning_rate": 4.430308630955506e-05,
      "loss": 1.0247,
      "step": 108500
    },
    {
      "epoch": 1.14,
      "learning_rate": 4.427683325107375e-05,
      "loss": 1.0304,
      "step": 109000
    },
    {
      "epoch": 1.15,
      "learning_rate": 4.425058019259244e-05,
      "loss": 1.0224,
      "step": 109500
    },
    {
      "epoch": 1.16,
      "learning_rate": 4.422432713411113e-05,
      "loss": 1.0136,
      "step": 110000
    },
    {
      "epoch": 1.16,
      "learning_rate": 4.419807407562981e-05,
      "loss": 1.025,
      "step": 110500
    },
    {
      "epoch": 1.17,
      "learning_rate": 4.41718210171485e-05,
      "loss": 1.0186,
      "step": 111000
    },
    {
      "epoch": 1.17,
      "learning_rate": 4.414556795866719e-05,
      "loss": 1.005,
      "step": 111500
    },
    {
      "epoch": 1.18,
      "learning_rate": 4.411931490018588e-05,
      "loss": 1.0194,
      "step": 112000
    },
    {
      "epoch": 1.18,
      "learning_rate": 4.409306184170456e-05,
      "loss": 1.0031,
      "step": 112500
    },
    {
      "epoch": 1.19,
      "learning_rate": 4.406680878322324e-05,
      "loss": 1.005,
      "step": 113000
    },
    {
      "epoch": 1.19,
      "learning_rate": 4.404055572474193e-05,
      "loss": 1.0117,
      "step": 113500
    },
    {
      "epoch": 1.2,
      "learning_rate": 4.401430266626062e-05,
      "loss": 1.0102,
      "step": 114000
    },
    {
      "epoch": 1.2,
      "learning_rate": 4.398804960777931e-05,
      "loss": 0.9986,
      "step": 114500
    },
    {
      "epoch": 1.21,
      "learning_rate": 4.3961796549298e-05,
      "loss": 0.9951,
      "step": 115000
    },
    {
      "epoch": 1.21,
      "learning_rate": 4.393554349081668e-05,
      "loss": 0.9946,
      "step": 115500
    },
    {
      "epoch": 1.22,
      "learning_rate": 4.390929043233537e-05,
      "loss": 1.0072,
      "step": 116000
    },
    {
      "epoch": 1.22,
      "learning_rate": 4.388303737385406e-05,
      "loss": 0.9914,
      "step": 116500
    },
    {
      "epoch": 1.23,
      "learning_rate": 4.385678431537275e-05,
      "loss": 1.0025,
      "step": 117000
    },
    {
      "epoch": 1.23,
      "learning_rate": 4.383053125689143e-05,
      "loss": 0.9984,
      "step": 117500
    },
    {
      "epoch": 1.24,
      "learning_rate": 4.380427819841011e-05,
      "loss": 0.9936,
      "step": 118000
    },
    {
      "epoch": 1.24,
      "learning_rate": 4.37780251399288e-05,
      "loss": 0.9868,
      "step": 118500
    },
    {
      "epoch": 1.25,
      "learning_rate": 4.375177208144749e-05,
      "loss": 0.9917,
      "step": 119000
    },
    {
      "epoch": 1.25,
      "learning_rate": 4.372551902296618e-05,
      "loss": 0.9911,
      "step": 119500
    },
    {
      "epoch": 1.26,
      "learning_rate": 4.369926596448487e-05,
      "loss": 0.9997,
      "step": 120000
    },
    {
      "epoch": 1.27,
      "learning_rate": 4.367301290600355e-05,
      "loss": 0.9793,
      "step": 120500
    },
    {
      "epoch": 1.27,
      "learning_rate": 4.364675984752224e-05,
      "loss": 0.9812,
      "step": 121000
    },
    {
      "epoch": 1.28,
      "learning_rate": 4.362050678904093e-05,
      "loss": 0.9751,
      "step": 121500
    },
    {
      "epoch": 1.28,
      "learning_rate": 4.359425373055962e-05,
      "loss": 0.9787,
      "step": 122000
    },
    {
      "epoch": 1.29,
      "learning_rate": 4.35680006720783e-05,
      "loss": 0.9836,
      "step": 122500
    },
    {
      "epoch": 1.29,
      "learning_rate": 4.354174761359698e-05,
      "loss": 0.9722,
      "step": 123000
    },
    {
      "epoch": 1.3,
      "learning_rate": 4.351549455511567e-05,
      "loss": 0.977,
      "step": 123500
    },
    {
      "epoch": 1.3,
      "learning_rate": 4.348924149663436e-05,
      "loss": 0.9722,
      "step": 124000
    },
    {
      "epoch": 1.31,
      "learning_rate": 4.346298843815305e-05,
      "loss": 0.973,
      "step": 124500
    },
    {
      "epoch": 1.31,
      "learning_rate": 4.343673537967173e-05,
      "loss": 0.9847,
      "step": 125000
    },
    {
      "epoch": 1.32,
      "learning_rate": 4.341048232119042e-05,
      "loss": 0.9748,
      "step": 125500
    },
    {
      "epoch": 1.32,
      "learning_rate": 4.338422926270911e-05,
      "loss": 0.9697,
      "step": 126000
    },
    {
      "epoch": 1.33,
      "learning_rate": 4.33579762042278e-05,
      "loss": 0.9721,
      "step": 126500
    },
    {
      "epoch": 1.33,
      "learning_rate": 4.3331723145746486e-05,
      "loss": 0.9737,
      "step": 127000
    },
    {
      "epoch": 1.34,
      "learning_rate": 4.330547008726517e-05,
      "loss": 0.9633,
      "step": 127500
    },
    {
      "epoch": 1.34,
      "learning_rate": 4.327921702878385e-05,
      "loss": 0.9631,
      "step": 128000
    },
    {
      "epoch": 1.35,
      "learning_rate": 4.325296397030254e-05,
      "loss": 0.9616,
      "step": 128500
    },
    {
      "epoch": 1.35,
      "learning_rate": 4.322671091182123e-05,
      "loss": 0.9658,
      "step": 129000
    },
    {
      "epoch": 1.36,
      "learning_rate": 4.320045785333992e-05,
      "loss": 0.9651,
      "step": 129500
    },
    {
      "epoch": 1.37,
      "learning_rate": 4.31742047948586e-05,
      "loss": 0.9635,
      "step": 130000
    },
    {
      "epoch": 1.37,
      "learning_rate": 4.314795173637729e-05,
      "loss": 0.9552,
      "step": 130500
    },
    {
      "epoch": 1.38,
      "learning_rate": 4.312169867789598e-05,
      "loss": 0.9521,
      "step": 131000
    },
    {
      "epoch": 1.38,
      "learning_rate": 4.3095445619414666e-05,
      "loss": 0.9515,
      "step": 131500
    },
    {
      "epoch": 1.39,
      "learning_rate": 4.3069192560933355e-05,
      "loss": 0.9594,
      "step": 132000
    },
    {
      "epoch": 1.39,
      "learning_rate": 4.304293950245204e-05,
      "loss": 0.9507,
      "step": 132500
    },
    {
      "epoch": 1.4,
      "learning_rate": 4.3016686443970726e-05,
      "loss": 0.9603,
      "step": 133000
    },
    {
      "epoch": 1.4,
      "learning_rate": 4.299043338548941e-05,
      "loss": 0.9429,
      "step": 133500
    },
    {
      "epoch": 1.41,
      "learning_rate": 4.29641803270081e-05,
      "loss": 0.9572,
      "step": 134000
    },
    {
      "epoch": 1.41,
      "learning_rate": 4.2937927268526786e-05,
      "loss": 0.9514,
      "step": 134500
    },
    {
      "epoch": 1.42,
      "learning_rate": 4.291167421004547e-05,
      "loss": 0.9414,
      "step": 135000
    },
    {
      "epoch": 1.42,
      "learning_rate": 4.288542115156416e-05,
      "loss": 0.9471,
      "step": 135500
    },
    {
      "epoch": 1.43,
      "learning_rate": 4.2859168093082846e-05,
      "loss": 0.9421,
      "step": 136000
    },
    {
      "epoch": 1.43,
      "learning_rate": 4.2832915034601535e-05,
      "loss": 0.9376,
      "step": 136500
    },
    {
      "epoch": 1.44,
      "learning_rate": 4.2806661976120224e-05,
      "loss": 0.9355,
      "step": 137000
    },
    {
      "epoch": 1.44,
      "learning_rate": 4.2780408917638906e-05,
      "loss": 0.9403,
      "step": 137500
    },
    {
      "epoch": 1.45,
      "learning_rate": 4.2754155859157595e-05,
      "loss": 0.9391,
      "step": 138000
    },
    {
      "epoch": 1.45,
      "learning_rate": 4.272790280067628e-05,
      "loss": 0.9382,
      "step": 138500
    },
    {
      "epoch": 1.46,
      "learning_rate": 4.2701649742194966e-05,
      "loss": 0.9315,
      "step": 139000
    },
    {
      "epoch": 1.46,
      "learning_rate": 4.2675396683713655e-05,
      "loss": 0.95,
      "step": 139500
    },
    {
      "epoch": 1.47,
      "learning_rate": 4.264914362523234e-05,
      "loss": 0.9369,
      "step": 140000
    },
    {
      "epoch": 1.48,
      "learning_rate": 4.2622890566751027e-05,
      "loss": 0.9349,
      "step": 140500
    },
    {
      "epoch": 1.48,
      "learning_rate": 4.2596637508269715e-05,
      "loss": 0.9358,
      "step": 141000
    },
    {
      "epoch": 1.49,
      "learning_rate": 4.2570384449788404e-05,
      "loss": 0.9284,
      "step": 141500
    },
    {
      "epoch": 1.49,
      "learning_rate": 4.254413139130709e-05,
      "loss": 0.9418,
      "step": 142000
    },
    {
      "epoch": 1.5,
      "learning_rate": 4.2517878332825776e-05,
      "loss": 0.9294,
      "step": 142500
    },
    {
      "epoch": 1.5,
      "learning_rate": 4.2491625274344464e-05,
      "loss": 0.9283,
      "step": 143000
    },
    {
      "epoch": 1.51,
      "learning_rate": 4.2465372215863153e-05,
      "loss": 0.9277,
      "step": 143500
    },
    {
      "epoch": 1.51,
      "learning_rate": 4.2439119157381836e-05,
      "loss": 0.9267,
      "step": 144000
    },
    {
      "epoch": 1.52,
      "learning_rate": 4.2412866098900525e-05,
      "loss": 0.9285,
      "step": 144500
    },
    {
      "epoch": 1.52,
      "learning_rate": 4.238661304041921e-05,
      "loss": 0.9275,
      "step": 145000
    },
    {
      "epoch": 1.53,
      "learning_rate": 4.2360359981937896e-05,
      "loss": 0.9255,
      "step": 145500
    },
    {
      "epoch": 1.53,
      "learning_rate": 4.2334106923456585e-05,
      "loss": 0.9142,
      "step": 146000
    },
    {
      "epoch": 1.54,
      "learning_rate": 4.2307853864975274e-05,
      "loss": 0.9197,
      "step": 146500
    },
    {
      "epoch": 1.54,
      "learning_rate": 4.228160080649396e-05,
      "loss": 0.9165,
      "step": 147000
    },
    {
      "epoch": 1.55,
      "learning_rate": 4.2255347748012645e-05,
      "loss": 0.9094,
      "step": 147500
    },
    {
      "epoch": 1.55,
      "learning_rate": 4.2229094689531334e-05,
      "loss": 0.9285,
      "step": 148000
    },
    {
      "epoch": 1.56,
      "learning_rate": 4.220284163105002e-05,
      "loss": 0.9207,
      "step": 148500
    },
    {
      "epoch": 1.56,
      "learning_rate": 4.2176588572568705e-05,
      "loss": 0.9176,
      "step": 149000
    },
    {
      "epoch": 1.57,
      "learning_rate": 4.2150335514087394e-05,
      "loss": 0.9229,
      "step": 149500
    },
    {
      "epoch": 1.58,
      "learning_rate": 4.2124082455606076e-05,
      "loss": 0.9135,
      "step": 150000
    },
    {
      "epoch": 1.58,
      "learning_rate": 4.2097829397124765e-05,
      "loss": 0.9146,
      "step": 150500
    },
    {
      "epoch": 1.59,
      "learning_rate": 4.2071576338643454e-05,
      "loss": 0.91,
      "step": 151000
    },
    {
      "epoch": 1.59,
      "learning_rate": 4.204532328016214e-05,
      "loss": 0.9085,
      "step": 151500
    },
    {
      "epoch": 1.6,
      "learning_rate": 4.201907022168083e-05,
      "loss": 0.9043,
      "step": 152000
    },
    {
      "epoch": 1.6,
      "learning_rate": 4.1992817163199514e-05,
      "loss": 0.908,
      "step": 152500
    },
    {
      "epoch": 1.61,
      "learning_rate": 4.19665641047182e-05,
      "loss": 0.8963,
      "step": 153000
    },
    {
      "epoch": 1.61,
      "learning_rate": 4.194031104623689e-05,
      "loss": 0.9092,
      "step": 153500
    },
    {
      "epoch": 1.62,
      "learning_rate": 4.1914057987755574e-05,
      "loss": 0.9067,
      "step": 154000
    },
    {
      "epoch": 1.62,
      "learning_rate": 4.188780492927426e-05,
      "loss": 0.9014,
      "step": 154500
    },
    {
      "epoch": 1.63,
      "learning_rate": 4.1861551870792945e-05,
      "loss": 0.9039,
      "step": 155000
    },
    {
      "epoch": 1.63,
      "learning_rate": 4.1835298812311634e-05,
      "loss": 0.9116,
      "step": 155500
    },
    {
      "epoch": 1.64,
      "learning_rate": 4.180904575383032e-05,
      "loss": 0.8929,
      "step": 156000
    },
    {
      "epoch": 1.64,
      "learning_rate": 4.178279269534901e-05,
      "loss": 0.9055,
      "step": 156500
    },
    {
      "epoch": 1.65,
      "learning_rate": 4.17565396368677e-05,
      "loss": 0.9066,
      "step": 157000
    },
    {
      "epoch": 1.65,
      "learning_rate": 4.173028657838638e-05,
      "loss": 0.8906,
      "step": 157500
    },
    {
      "epoch": 1.66,
      "learning_rate": 4.170403351990507e-05,
      "loss": 0.8921,
      "step": 158000
    },
    {
      "epoch": 1.66,
      "learning_rate": 4.167778046142376e-05,
      "loss": 0.8976,
      "step": 158500
    },
    {
      "epoch": 1.67,
      "learning_rate": 4.165152740294245e-05,
      "loss": 0.9049,
      "step": 159000
    },
    {
      "epoch": 1.67,
      "learning_rate": 4.162527434446113e-05,
      "loss": 0.8943,
      "step": 159500
    },
    {
      "epoch": 1.68,
      "learning_rate": 4.1599021285979814e-05,
      "loss": 0.8942,
      "step": 160000
    },
    {
      "epoch": 1.69,
      "learning_rate": 4.15727682274985e-05,
      "loss": 0.8912,
      "step": 160500
    },
    {
      "epoch": 1.69,
      "learning_rate": 4.154651516901719e-05,
      "loss": 0.8841,
      "step": 161000
    },
    {
      "epoch": 1.7,
      "learning_rate": 4.152026211053588e-05,
      "loss": 0.9004,
      "step": 161500
    },
    {
      "epoch": 1.7,
      "learning_rate": 4.149400905205457e-05,
      "loss": 0.8956,
      "step": 162000
    },
    {
      "epoch": 1.71,
      "learning_rate": 4.146775599357325e-05,
      "loss": 0.8906,
      "step": 162500
    },
    {
      "epoch": 1.71,
      "learning_rate": 4.144150293509194e-05,
      "loss": 0.8934,
      "step": 163000
    },
    {
      "epoch": 1.72,
      "learning_rate": 4.141524987661063e-05,
      "loss": 0.8885,
      "step": 163500
    },
    {
      "epoch": 1.72,
      "learning_rate": 4.138899681812932e-05,
      "loss": 0.8995,
      "step": 164000
    },
    {
      "epoch": 1.73,
      "learning_rate": 4.1362743759648e-05,
      "loss": 0.8887,
      "step": 164500
    },
    {
      "epoch": 1.73,
      "learning_rate": 4.133649070116668e-05,
      "loss": 0.8735,
      "step": 165000
    },
    {
      "epoch": 1.74,
      "learning_rate": 4.131023764268537e-05,
      "loss": 0.8785,
      "step": 165500
    },
    {
      "epoch": 1.74,
      "learning_rate": 4.128398458420406e-05,
      "loss": 0.8879,
      "step": 166000
    },
    {
      "epoch": 1.75,
      "learning_rate": 4.125773152572275e-05,
      "loss": 0.8759,
      "step": 166500
    },
    {
      "epoch": 1.75,
      "learning_rate": 4.123147846724144e-05,
      "loss": 0.875,
      "step": 167000
    },
    {
      "epoch": 1.76,
      "learning_rate": 4.120522540876012e-05,
      "loss": 0.8797,
      "step": 167500
    },
    {
      "epoch": 1.76,
      "learning_rate": 4.117897235027881e-05,
      "loss": 0.8764,
      "step": 168000
    },
    {
      "epoch": 1.77,
      "learning_rate": 4.11527192917975e-05,
      "loss": 0.8783,
      "step": 168500
    },
    {
      "epoch": 1.77,
      "learning_rate": 4.112646623331619e-05,
      "loss": 0.8866,
      "step": 169000
    },
    {
      "epoch": 1.78,
      "learning_rate": 4.110021317483487e-05,
      "loss": 0.8762,
      "step": 169500
    },
    {
      "epoch": 1.79,
      "learning_rate": 4.107396011635355e-05,
      "loss": 0.8778,
      "step": 170000
    },
    {
      "epoch": 1.79,
      "learning_rate": 4.104770705787224e-05,
      "loss": 0.8675,
      "step": 170500
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.102145399939093e-05,
      "loss": 0.8731,
      "step": 171000
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.099520094090962e-05,
      "loss": 0.874,
      "step": 171500
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.09689478824283e-05,
      "loss": 0.8679,
      "step": 172000
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.094269482394699e-05,
      "loss": 0.8638,
      "step": 172500
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.091644176546568e-05,
      "loss": 0.8808,
      "step": 173000
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.089018870698437e-05,
      "loss": 0.8656,
      "step": 173500
    },
    {
      "epoch": 1.83,
      "learning_rate": 4.086393564850306e-05,
      "loss": 0.8615,
      "step": 174000
    },
    {
      "epoch": 1.83,
      "learning_rate": 4.083768259002174e-05,
      "loss": 0.8685,
      "step": 174500
    },
    {
      "epoch": 1.84,
      "learning_rate": 4.081142953154042e-05,
      "loss": 0.8648,
      "step": 175000
    },
    {
      "epoch": 1.84,
      "learning_rate": 4.078517647305911e-05,
      "loss": 0.8726,
      "step": 175500
    },
    {
      "epoch": 1.85,
      "learning_rate": 4.07589234145778e-05,
      "loss": 0.864,
      "step": 176000
    },
    {
      "epoch": 1.85,
      "learning_rate": 4.073267035609649e-05,
      "loss": 0.868,
      "step": 176500
    },
    {
      "epoch": 1.86,
      "learning_rate": 4.070641729761517e-05,
      "loss": 0.8476,
      "step": 177000
    },
    {
      "epoch": 1.86,
      "learning_rate": 4.068016423913386e-05,
      "loss": 0.8631,
      "step": 177500
    },
    {
      "epoch": 1.87,
      "learning_rate": 4.065391118065255e-05,
      "loss": 0.866,
      "step": 178000
    },
    {
      "epoch": 1.87,
      "learning_rate": 4.062765812217124e-05,
      "loss": 0.8604,
      "step": 178500
    },
    {
      "epoch": 1.88,
      "learning_rate": 4.0601405063689926e-05,
      "loss": 0.8663,
      "step": 179000
    },
    {
      "epoch": 1.88,
      "learning_rate": 4.057515200520861e-05,
      "loss": 0.8575,
      "step": 179500
    },
    {
      "epoch": 1.89,
      "learning_rate": 4.05488989467273e-05,
      "loss": 0.852,
      "step": 180000
    },
    {
      "epoch": 1.9,
      "learning_rate": 4.052264588824598e-05,
      "loss": 0.847,
      "step": 180500
    },
    {
      "epoch": 1.9,
      "learning_rate": 4.049639282976467e-05,
      "loss": 0.8608,
      "step": 181000
    },
    {
      "epoch": 1.91,
      "learning_rate": 4.047013977128336e-05,
      "loss": 0.8591,
      "step": 181500
    },
    {
      "epoch": 1.91,
      "learning_rate": 4.044388671280204e-05,
      "loss": 0.8517,
      "step": 182000
    },
    {
      "epoch": 1.92,
      "learning_rate": 4.041763365432073e-05,
      "loss": 0.8493,
      "step": 182500
    },
    {
      "epoch": 1.92,
      "learning_rate": 4.039138059583942e-05,
      "loss": 0.851,
      "step": 183000
    },
    {
      "epoch": 1.93,
      "learning_rate": 4.0365127537358106e-05,
      "loss": 0.8584,
      "step": 183500
    },
    {
      "epoch": 1.93,
      "learning_rate": 4.0338874478876795e-05,
      "loss": 0.8501,
      "step": 184000
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.031262142039548e-05,
      "loss": 0.8605,
      "step": 184500
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.0286368361914166e-05,
      "loss": 0.8459,
      "step": 185000
    },
    {
      "epoch": 1.95,
      "learning_rate": 4.026011530343285e-05,
      "loss": 0.8507,
      "step": 185500
    },
    {
      "epoch": 1.95,
      "learning_rate": 4.023386224495154e-05,
      "loss": 0.8484,
      "step": 186000
    },
    {
      "epoch": 1.96,
      "learning_rate": 4.0207609186470226e-05,
      "loss": 0.8486,
      "step": 186500
    },
    {
      "epoch": 1.96,
      "learning_rate": 4.018135612798891e-05,
      "loss": 0.8542,
      "step": 187000
    },
    {
      "epoch": 1.97,
      "learning_rate": 4.01551030695076e-05,
      "loss": 0.8454,
      "step": 187500
    },
    {
      "epoch": 1.97,
      "learning_rate": 4.0128850011026286e-05,
      "loss": 0.8397,
      "step": 188000
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.0102596952544975e-05,
      "loss": 0.8448,
      "step": 188500
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.0076343894063664e-05,
      "loss": 0.8396,
      "step": 189000
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.0050090835582347e-05,
      "loss": 0.8399,
      "step": 189500
    },
    {
      "epoch": 2.0,
      "learning_rate": 4.0023837777101035e-05,
      "loss": 0.8431,
      "step": 190000
    },
    {
      "epoch": 2.0,
      "learning_rate": 3.999758471861972e-05,
      "loss": 0.8345,
      "step": 190500
    },
    {
      "epoch": 2.01,
      "learning_rate": 3.9971331660138407e-05,
      "loss": 0.8319,
      "step": 191000
    },
    {
      "epoch": 2.01,
      "learning_rate": 3.9945078601657096e-05,
      "loss": 0.8412,
      "step": 191500
    },
    {
      "epoch": 2.02,
      "learning_rate": 3.991882554317578e-05,
      "loss": 0.8371,
      "step": 192000
    },
    {
      "epoch": 2.02,
      "learning_rate": 3.989257248469447e-05,
      "loss": 0.8316,
      "step": 192500
    },
    {
      "epoch": 2.03,
      "learning_rate": 3.9866319426213156e-05,
      "loss": 0.8318,
      "step": 193000
    },
    {
      "epoch": 2.03,
      "learning_rate": 3.9840066367731845e-05,
      "loss": 0.8298,
      "step": 193500
    },
    {
      "epoch": 2.04,
      "learning_rate": 3.9813813309250533e-05,
      "loss": 0.8346,
      "step": 194000
    },
    {
      "epoch": 2.04,
      "learning_rate": 3.9787560250769216e-05,
      "loss": 0.8323,
      "step": 194500
    },
    {
      "epoch": 2.05,
      "learning_rate": 3.9761307192287905e-05,
      "loss": 0.837,
      "step": 195000
    },
    {
      "epoch": 2.05,
      "learning_rate": 3.9735054133806594e-05,
      "loss": 0.8258,
      "step": 195500
    },
    {
      "epoch": 2.06,
      "learning_rate": 3.9708801075325276e-05,
      "loss": 0.8287,
      "step": 196000
    },
    {
      "epoch": 2.06,
      "learning_rate": 3.9682548016843965e-05,
      "loss": 0.8357,
      "step": 196500
    },
    {
      "epoch": 2.07,
      "learning_rate": 3.965629495836265e-05,
      "loss": 0.8338,
      "step": 197000
    },
    {
      "epoch": 2.07,
      "learning_rate": 3.9630041899881336e-05,
      "loss": 0.8262,
      "step": 197500
    },
    {
      "epoch": 2.08,
      "learning_rate": 3.9603788841400025e-05,
      "loss": 0.8322,
      "step": 198000
    },
    {
      "epoch": 2.08,
      "learning_rate": 3.9577535782918714e-05,
      "loss": 0.8202,
      "step": 198500
    },
    {
      "epoch": 2.09,
      "learning_rate": 3.95512827244374e-05,
      "loss": 0.8293,
      "step": 199000
    },
    {
      "epoch": 2.09,
      "learning_rate": 3.9525029665956085e-05,
      "loss": 0.8232,
      "step": 199500
    },
    {
      "epoch": 2.1,
      "learning_rate": 3.9498776607474774e-05,
      "loss": 0.8137,
      "step": 200000
    },
    {
      "epoch": 2.11,
      "learning_rate": 3.947252354899346e-05,
      "loss": 0.8263,
      "step": 200500
    },
    {
      "epoch": 2.11,
      "learning_rate": 3.9446270490512145e-05,
      "loss": 0.8259,
      "step": 201000
    },
    {
      "epoch": 2.12,
      "learning_rate": 3.9420017432030834e-05,
      "loss": 0.8292,
      "step": 201500
    },
    {
      "epoch": 2.12,
      "learning_rate": 3.9393764373549516e-05,
      "loss": 0.8193,
      "step": 202000
    },
    {
      "epoch": 2.13,
      "learning_rate": 3.9367511315068205e-05,
      "loss": 0.8221,
      "step": 202500
    },
    {
      "epoch": 2.13,
      "learning_rate": 3.9341258256586894e-05,
      "loss": 0.8206,
      "step": 203000
    },
    {
      "epoch": 2.14,
      "learning_rate": 3.931500519810558e-05,
      "loss": 0.8208,
      "step": 203500
    },
    {
      "epoch": 2.14,
      "learning_rate": 3.928875213962427e-05,
      "loss": 0.8249,
      "step": 204000
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.9262499081142954e-05,
      "loss": 0.8196,
      "step": 204500
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.923624602266164e-05,
      "loss": 0.8158,
      "step": 205000
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.920999296418033e-05,
      "loss": 0.8198,
      "step": 205500
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.918373990569902e-05,
      "loss": 0.8182,
      "step": 206000
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.91574868472177e-05,
      "loss": 0.8218,
      "step": 206500
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.9131233788736385e-05,
      "loss": 0.8194,
      "step": 207000
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.9104980730255074e-05,
      "loss": 0.8186,
      "step": 207500
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.907872767177376e-05,
      "loss": 0.8149,
      "step": 208000
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.905247461329245e-05,
      "loss": 0.8144,
      "step": 208500
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.902622155481114e-05,
      "loss": 0.8101,
      "step": 209000
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.899996849632982e-05,
      "loss": 0.8014,
      "step": 209500
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.897371543784851e-05,
      "loss": 0.8062,
      "step": 210000
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.89474623793672e-05,
      "loss": 0.8111,
      "step": 210500
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.892120932088589e-05,
      "loss": 0.8094,
      "step": 211000
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.889495626240457e-05,
      "loss": 0.8077,
      "step": 211500
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.8868703203923254e-05,
      "loss": 0.8091,
      "step": 212000
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.884245014544194e-05,
      "loss": 0.8056,
      "step": 212500
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.881619708696063e-05,
      "loss": 0.806,
      "step": 213000
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.878994402847932e-05,
      "loss": 0.8081,
      "step": 213500
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.876369096999801e-05,
      "loss": 0.8067,
      "step": 214000
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.873743791151669e-05,
      "loss": 0.8065,
      "step": 214500
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.871118485303538e-05,
      "loss": 0.8107,
      "step": 215000
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.868493179455407e-05,
      "loss": 0.8032,
      "step": 215500
    },
    {
      "epoch": 2.27,
      "learning_rate": 3.865867873607276e-05,
      "loss": 0.7968,
      "step": 216000
    },
    {
      "epoch": 2.27,
      "learning_rate": 3.863242567759144e-05,
      "loss": 0.803,
      "step": 216500
    },
    {
      "epoch": 2.28,
      "learning_rate": 3.860617261911012e-05,
      "loss": 0.8104,
      "step": 217000
    },
    {
      "epoch": 2.28,
      "learning_rate": 3.857991956062881e-05,
      "loss": 0.8028,
      "step": 217500
    },
    {
      "epoch": 2.29,
      "learning_rate": 3.85536665021475e-05,
      "loss": 0.8012,
      "step": 218000
    },
    {
      "epoch": 2.29,
      "learning_rate": 3.852741344366619e-05,
      "loss": 0.7979,
      "step": 218500
    },
    {
      "epoch": 2.3,
      "learning_rate": 3.850116038518488e-05,
      "loss": 0.7936,
      "step": 219000
    },
    {
      "epoch": 2.31,
      "learning_rate": 3.847490732670356e-05,
      "loss": 0.8056,
      "step": 219500
    },
    {
      "epoch": 2.31,
      "learning_rate": 3.844865426822225e-05,
      "loss": 0.8029,
      "step": 220000
    },
    {
      "epoch": 2.32,
      "learning_rate": 3.842240120974094e-05,
      "loss": 0.8066,
      "step": 220500
    },
    {
      "epoch": 2.32,
      "learning_rate": 3.839614815125963e-05,
      "loss": 0.8059,
      "step": 221000
    },
    {
      "epoch": 2.33,
      "learning_rate": 3.836989509277831e-05,
      "loss": 0.8035,
      "step": 221500
    },
    {
      "epoch": 2.33,
      "learning_rate": 3.834364203429699e-05,
      "loss": 0.7974,
      "step": 222000
    },
    {
      "epoch": 2.34,
      "learning_rate": 3.831738897581568e-05,
      "loss": 0.7918,
      "step": 222500
    },
    {
      "epoch": 2.34,
      "learning_rate": 3.829113591733437e-05,
      "loss": 0.7994,
      "step": 223000
    },
    {
      "epoch": 2.35,
      "learning_rate": 3.826488285885306e-05,
      "loss": 0.8033,
      "step": 223500
    },
    {
      "epoch": 2.35,
      "learning_rate": 3.823862980037174e-05,
      "loss": 0.7896,
      "step": 224000
    },
    {
      "epoch": 2.36,
      "learning_rate": 3.821237674189043e-05,
      "loss": 0.7848,
      "step": 224500
    },
    {
      "epoch": 2.36,
      "learning_rate": 3.818612368340912e-05,
      "loss": 0.7973,
      "step": 225000
    },
    {
      "epoch": 2.37,
      "learning_rate": 3.815987062492781e-05,
      "loss": 0.7887,
      "step": 225500
    },
    {
      "epoch": 2.37,
      "learning_rate": 3.81336175664465e-05,
      "loss": 0.7881,
      "step": 226000
    },
    {
      "epoch": 2.38,
      "learning_rate": 3.810736450796518e-05,
      "loss": 0.7904,
      "step": 226500
    },
    {
      "epoch": 2.38,
      "learning_rate": 3.808111144948387e-05,
      "loss": 0.7912,
      "step": 227000
    },
    {
      "epoch": 2.39,
      "learning_rate": 3.805485839100255e-05,
      "loss": 0.7966,
      "step": 227500
    },
    {
      "epoch": 2.39,
      "learning_rate": 3.802860533252124e-05,
      "loss": 0.7877,
      "step": 228000
    },
    {
      "epoch": 2.4,
      "learning_rate": 3.800235227403993e-05,
      "loss": 0.7855,
      "step": 228500
    },
    {
      "epoch": 2.4,
      "learning_rate": 3.797609921555861e-05,
      "loss": 0.7889,
      "step": 229000
    },
    {
      "epoch": 2.41,
      "learning_rate": 3.79498461570773e-05,
      "loss": 0.793,
      "step": 229500
    },
    {
      "epoch": 2.42,
      "learning_rate": 3.792359309859599e-05,
      "loss": 0.7964,
      "step": 230000
    },
    {
      "epoch": 2.42,
      "learning_rate": 3.789734004011468e-05,
      "loss": 0.783,
      "step": 230500
    },
    {
      "epoch": 2.43,
      "learning_rate": 3.7871086981633366e-05,
      "loss": 0.798,
      "step": 231000
    },
    {
      "epoch": 2.43,
      "learning_rate": 3.784483392315205e-05,
      "loss": 0.7739,
      "step": 231500
    },
    {
      "epoch": 2.44,
      "learning_rate": 3.781858086467074e-05,
      "loss": 0.7927,
      "step": 232000
    },
    {
      "epoch": 2.44,
      "learning_rate": 3.779232780618942e-05,
      "loss": 0.784,
      "step": 232500
    },
    {
      "epoch": 2.45,
      "learning_rate": 3.776607474770811e-05,
      "loss": 0.7882,
      "step": 233000
    },
    {
      "epoch": 2.45,
      "learning_rate": 3.77398216892268e-05,
      "loss": 0.7853,
      "step": 233500
    },
    {
      "epoch": 2.46,
      "learning_rate": 3.771356863074548e-05,
      "loss": 0.7934,
      "step": 234000
    },
    {
      "epoch": 2.46,
      "learning_rate": 3.768731557226417e-05,
      "loss": 0.7909,
      "step": 234500
    },
    {
      "epoch": 2.47,
      "learning_rate": 3.766106251378286e-05,
      "loss": 0.7731,
      "step": 235000
    },
    {
      "epoch": 2.47,
      "learning_rate": 3.7634809455301546e-05,
      "loss": 0.7886,
      "step": 235500
    },
    {
      "epoch": 2.48,
      "learning_rate": 3.7608556396820235e-05,
      "loss": 0.7792,
      "step": 236000
    },
    {
      "epoch": 2.48,
      "learning_rate": 3.758230333833892e-05,
      "loss": 0.7848,
      "step": 236500
    },
    {
      "epoch": 2.49,
      "learning_rate": 3.7556050279857606e-05,
      "loss": 0.7832,
      "step": 237000
    },
    {
      "epoch": 2.49,
      "learning_rate": 3.752979722137629e-05,
      "loss": 0.7716,
      "step": 237500
    },
    {
      "epoch": 2.5,
      "learning_rate": 3.750354416289498e-05,
      "loss": 0.7882,
      "step": 238000
    },
    {
      "epoch": 2.5,
      "learning_rate": 3.7477291104413667e-05,
      "loss": 0.7744,
      "step": 238500
    },
    {
      "epoch": 2.51,
      "learning_rate": 3.745103804593235e-05,
      "loss": 0.7804,
      "step": 239000
    },
    {
      "epoch": 2.52,
      "learning_rate": 3.742478498745104e-05,
      "loss": 0.786,
      "step": 239500
    },
    {
      "epoch": 2.52,
      "learning_rate": 3.7398531928969727e-05,
      "loss": 0.7844,
      "step": 240000
    },
    {
      "epoch": 2.53,
      "learning_rate": 3.7372278870488416e-05,
      "loss": 0.7746,
      "step": 240500
    },
    {
      "epoch": 2.53,
      "learning_rate": 3.7346025812007104e-05,
      "loss": 0.784,
      "step": 241000
    },
    {
      "epoch": 2.54,
      "learning_rate": 3.731977275352579e-05,
      "loss": 0.7689,
      "step": 241500
    },
    {
      "epoch": 2.54,
      "learning_rate": 3.7293519695044476e-05,
      "loss": 0.7767,
      "step": 242000
    },
    {
      "epoch": 2.55,
      "learning_rate": 3.7267266636563165e-05,
      "loss": 0.7797,
      "step": 242500
    },
    {
      "epoch": 2.55,
      "learning_rate": 3.724101357808185e-05,
      "loss": 0.7655,
      "step": 243000
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.7214760519600536e-05,
      "loss": 0.769,
      "step": 243500
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.718850746111922e-05,
      "loss": 0.7718,
      "step": 244000
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.716225440263791e-05,
      "loss": 0.7714,
      "step": 244500
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.7136001344156596e-05,
      "loss": 0.7745,
      "step": 245000
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.7109748285675285e-05,
      "loss": 0.7779,
      "step": 245500
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.7083495227193974e-05,
      "loss": 0.7743,
      "step": 246000
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7057242168712656e-05,
      "loss": 0.7762,
      "step": 246500
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7030989110231345e-05,
      "loss": 0.7705,
      "step": 247000
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.7004736051750034e-05,
      "loss": 0.7609,
      "step": 247500
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.6978482993268716e-05,
      "loss": 0.7728,
      "step": 248000
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.6952229934787405e-05,
      "loss": 0.7674,
      "step": 248500
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.692597687630609e-05,
      "loss": 0.7668,
      "step": 249000
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.6899723817824776e-05,
      "loss": 0.7705,
      "step": 249500
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.6873470759343465e-05,
      "loss": 0.765,
      "step": 250000
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.6847217700862154e-05,
      "loss": 0.7723,
      "step": 250500
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.682096464238084e-05,
      "loss": 0.7637,
      "step": 251000
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.6794711583899525e-05,
      "loss": 0.7608,
      "step": 251500
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.6768458525418214e-05,
      "loss": 0.7578,
      "step": 252000
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.67422054669369e-05,
      "loss": 0.7676,
      "step": 252500
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.671595240845559e-05,
      "loss": 0.7556,
      "step": 253000
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.6689699349974274e-05,
      "loss": 0.7637,
      "step": 253500
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.6663446291492956e-05,
      "loss": 0.7625,
      "step": 254000
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.6637193233011645e-05,
      "loss": 0.7711,
      "step": 254500
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.6610940174530334e-05,
      "loss": 0.7656,
      "step": 255000
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.658468711604902e-05,
      "loss": 0.7668,
      "step": 255500
    },
    {
      "epoch": 2.69,
      "learning_rate": 3.655843405756771e-05,
      "loss": 0.763,
      "step": 256000
    },
    {
      "epoch": 2.69,
      "learning_rate": 3.6532180999086394e-05,
      "loss": 0.7679,
      "step": 256500
    },
    {
      "epoch": 2.7,
      "learning_rate": 3.650592794060508e-05,
      "loss": 0.762,
      "step": 257000
    },
    {
      "epoch": 2.7,
      "learning_rate": 3.647967488212377e-05,
      "loss": 0.7756,
      "step": 257500
    },
    {
      "epoch": 2.71,
      "learning_rate": 3.645342182364246e-05,
      "loss": 0.7676,
      "step": 258000
    },
    {
      "epoch": 2.71,
      "learning_rate": 3.642716876516114e-05,
      "loss": 0.7635,
      "step": 258500
    },
    {
      "epoch": 2.72,
      "learning_rate": 3.6400915706679825e-05,
      "loss": 0.7596,
      "step": 259000
    },
    {
      "epoch": 2.73,
      "learning_rate": 3.6374662648198514e-05,
      "loss": 0.7601,
      "step": 259500
    },
    {
      "epoch": 2.73,
      "learning_rate": 3.63484095897172e-05,
      "loss": 0.7627,
      "step": 260000
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.632215653123589e-05,
      "loss": 0.7712,
      "step": 260500
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.629590347275458e-05,
      "loss": 0.7512,
      "step": 261000
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.626965041427326e-05,
      "loss": 0.7605,
      "step": 261500
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.624339735579195e-05,
      "loss": 0.76,
      "step": 262000
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.621714429731064e-05,
      "loss": 0.7592,
      "step": 262500
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.619089123882933e-05,
      "loss": 0.7612,
      "step": 263000
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.616463818034801e-05,
      "loss": 0.759,
      "step": 263500
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.6138385121866694e-05,
      "loss": 0.755,
      "step": 264000
    },
    {
      "epoch": 2.78,
      "learning_rate": 3.611213206338538e-05,
      "loss": 0.7639,
      "step": 264500
    },
    {
      "epoch": 2.78,
      "learning_rate": 3.608587900490407e-05,
      "loss": 0.7516,
      "step": 265000
    },
    {
      "epoch": 2.79,
      "learning_rate": 3.605962594642276e-05,
      "loss": 0.7511,
      "step": 265500
    },
    {
      "epoch": 2.79,
      "learning_rate": 3.603337288794145e-05,
      "loss": 0.7564,
      "step": 266000
    },
    {
      "epoch": 2.8,
      "learning_rate": 3.600711982946013e-05,
      "loss": 0.7547,
      "step": 266500
    },
    {
      "epoch": 2.8,
      "learning_rate": 3.598086677097882e-05,
      "loss": 0.7534,
      "step": 267000
    },
    {
      "epoch": 2.81,
      "learning_rate": 3.595461371249751e-05,
      "loss": 0.7483,
      "step": 267500
    },
    {
      "epoch": 2.81,
      "learning_rate": 3.59283606540162e-05,
      "loss": 0.7559,
      "step": 268000
    },
    {
      "epoch": 2.82,
      "learning_rate": 3.590210759553488e-05,
      "loss": 0.7528,
      "step": 268500
    },
    {
      "epoch": 2.82,
      "learning_rate": 3.5875854537053563e-05,
      "loss": 0.7519,
      "step": 269000
    },
    {
      "epoch": 2.83,
      "learning_rate": 3.584960147857225e-05,
      "loss": 0.7567,
      "step": 269500
    },
    {
      "epoch": 2.84,
      "learning_rate": 3.582334842009094e-05,
      "loss": 0.7557,
      "step": 270000
    },
    {
      "epoch": 2.84,
      "learning_rate": 3.579709536160963e-05,
      "loss": 0.7472,
      "step": 270500
    },
    {
      "epoch": 2.85,
      "learning_rate": 3.577084230312831e-05,
      "loss": 0.749,
      "step": 271000
    },
    {
      "epoch": 2.85,
      "learning_rate": 3.5744589244647e-05,
      "loss": 0.7431,
      "step": 271500
    },
    {
      "epoch": 2.86,
      "learning_rate": 3.571833618616569e-05,
      "loss": 0.7476,
      "step": 272000
    },
    {
      "epoch": 2.86,
      "learning_rate": 3.569208312768438e-05,
      "loss": 0.7458,
      "step": 272500
    },
    {
      "epoch": 2.87,
      "learning_rate": 3.566583006920307e-05,
      "loss": 0.7484,
      "step": 273000
    },
    {
      "epoch": 2.87,
      "learning_rate": 3.563957701072175e-05,
      "loss": 0.7427,
      "step": 273500
    },
    {
      "epoch": 2.88,
      "learning_rate": 3.561332395224044e-05,
      "loss": 0.7414,
      "step": 274000
    },
    {
      "epoch": 2.88,
      "learning_rate": 3.558707089375912e-05,
      "loss": 0.7486,
      "step": 274500
    },
    {
      "epoch": 2.89,
      "learning_rate": 3.556081783527781e-05,
      "loss": 0.7419,
      "step": 275000
    },
    {
      "epoch": 2.89,
      "learning_rate": 3.55345647767965e-05,
      "loss": 0.7468,
      "step": 275500
    },
    {
      "epoch": 2.9,
      "learning_rate": 3.550831171831518e-05,
      "loss": 0.7465,
      "step": 276000
    },
    {
      "epoch": 2.9,
      "learning_rate": 3.548205865983387e-05,
      "loss": 0.7429,
      "step": 276500
    },
    {
      "epoch": 2.91,
      "learning_rate": 3.545580560135256e-05,
      "loss": 0.753,
      "step": 277000
    },
    {
      "epoch": 2.91,
      "learning_rate": 3.542955254287125e-05,
      "loss": 0.7347,
      "step": 277500
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.540329948438994e-05,
      "loss": 0.7376,
      "step": 278000
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.537704642590862e-05,
      "loss": 0.738,
      "step": 278500
    },
    {
      "epoch": 2.93,
      "learning_rate": 3.535079336742731e-05,
      "loss": 0.7433,
      "step": 279000
    },
    {
      "epoch": 2.94,
      "learning_rate": 3.532454030894599e-05,
      "loss": 0.7389,
      "step": 279500
    },
    {
      "epoch": 2.94,
      "learning_rate": 3.529828725046468e-05,
      "loss": 0.7485,
      "step": 280000
    },
    {
      "epoch": 2.95,
      "learning_rate": 3.527203419198337e-05,
      "loss": 0.7462,
      "step": 280500
    },
    {
      "epoch": 2.95,
      "learning_rate": 3.524578113350205e-05,
      "loss": 0.7416,
      "step": 281000
    },
    {
      "epoch": 2.96,
      "learning_rate": 3.521952807502074e-05,
      "loss": 0.7363,
      "step": 281500
    },
    {
      "epoch": 2.96,
      "learning_rate": 3.519327501653943e-05,
      "loss": 0.7414,
      "step": 282000
    },
    {
      "epoch": 2.97,
      "learning_rate": 3.516702195805812e-05,
      "loss": 0.7326,
      "step": 282500
    },
    {
      "epoch": 2.97,
      "learning_rate": 3.5140768899576806e-05,
      "loss": 0.7477,
      "step": 283000
    },
    {
      "epoch": 2.98,
      "learning_rate": 3.511451584109549e-05,
      "loss": 0.7283,
      "step": 283500
    },
    {
      "epoch": 2.98,
      "learning_rate": 3.508826278261418e-05,
      "loss": 0.7338,
      "step": 284000
    },
    {
      "epoch": 2.99,
      "learning_rate": 3.506200972413286e-05,
      "loss": 0.735,
      "step": 284500
    },
    {
      "epoch": 2.99,
      "learning_rate": 3.503575666565155e-05,
      "loss": 0.7345,
      "step": 285000
    },
    {
      "epoch": 3.0,
      "learning_rate": 3.500950360717024e-05,
      "loss": 0.7309,
      "step": 285500
    },
    {
      "epoch": 3.0,
      "learning_rate": 3.498325054868892e-05,
      "loss": 0.7333,
      "step": 286000
    },
    {
      "epoch": 3.01,
      "learning_rate": 3.495699749020761e-05,
      "loss": 0.7251,
      "step": 286500
    },
    {
      "epoch": 3.01,
      "learning_rate": 3.49307444317263e-05,
      "loss": 0.7272,
      "step": 287000
    },
    {
      "epoch": 3.02,
      "learning_rate": 3.4904491373244987e-05,
      "loss": 0.7222,
      "step": 287500
    },
    {
      "epoch": 3.02,
      "learning_rate": 3.4878238314763676e-05,
      "loss": 0.7324,
      "step": 288000
    },
    {
      "epoch": 3.03,
      "learning_rate": 3.485198525628236e-05,
      "loss": 0.7362,
      "step": 288500
    },
    {
      "epoch": 3.03,
      "learning_rate": 3.482573219780105e-05,
      "loss": 0.7204,
      "step": 289000
    },
    {
      "epoch": 3.04,
      "learning_rate": 3.4799479139319736e-05,
      "loss": 0.7367,
      "step": 289500
    },
    {
      "epoch": 3.05,
      "learning_rate": 3.477322608083842e-05,
      "loss": 0.7258,
      "step": 290000
    },
    {
      "epoch": 3.05,
      "learning_rate": 3.474697302235711e-05,
      "loss": 0.7301,
      "step": 290500
    },
    {
      "epoch": 3.06,
      "learning_rate": 3.472071996387579e-05,
      "loss": 0.7321,
      "step": 291000
    },
    {
      "epoch": 3.06,
      "learning_rate": 3.469446690539448e-05,
      "loss": 0.7178,
      "step": 291500
    },
    {
      "epoch": 3.07,
      "learning_rate": 3.466821384691317e-05,
      "loss": 0.7282,
      "step": 292000
    },
    {
      "epoch": 3.07,
      "learning_rate": 3.4641960788431856e-05,
      "loss": 0.7255,
      "step": 292500
    },
    {
      "epoch": 3.08,
      "learning_rate": 3.4615707729950545e-05,
      "loss": 0.7281,
      "step": 293000
    },
    {
      "epoch": 3.08,
      "learning_rate": 3.458945467146923e-05,
      "loss": 0.729,
      "step": 293500
    },
    {
      "epoch": 3.09,
      "learning_rate": 3.4563201612987916e-05,
      "loss": 0.7209,
      "step": 294000
    },
    {
      "epoch": 3.09,
      "learning_rate": 3.4536948554506605e-05,
      "loss": 0.7277,
      "step": 294500
    },
    {
      "epoch": 3.1,
      "learning_rate": 3.451069549602529e-05,
      "loss": 0.7303,
      "step": 295000
    },
    {
      "epoch": 3.1,
      "learning_rate": 3.4484442437543976e-05,
      "loss": 0.7215,
      "step": 295500
    },
    {
      "epoch": 3.11,
      "learning_rate": 3.445818937906266e-05,
      "loss": 0.7231,
      "step": 296000
    },
    {
      "epoch": 3.11,
      "learning_rate": 3.443193632058135e-05,
      "loss": 0.7271,
      "step": 296500
    },
    {
      "epoch": 3.12,
      "learning_rate": 3.4405683262100036e-05,
      "loss": 0.7233,
      "step": 297000
    },
    {
      "epoch": 3.12,
      "learning_rate": 3.4379430203618725e-05,
      "loss": 0.7243,
      "step": 297500
    },
    {
      "epoch": 3.13,
      "learning_rate": 3.4353177145137414e-05,
      "loss": 0.7188,
      "step": 298000
    },
    {
      "epoch": 3.13,
      "learning_rate": 3.4326924086656096e-05,
      "loss": 0.7243,
      "step": 298500
    },
    {
      "epoch": 3.14,
      "learning_rate": 3.4300671028174785e-05,
      "loss": 0.7238,
      "step": 299000
    },
    {
      "epoch": 3.15,
      "learning_rate": 3.4274417969693474e-05,
      "loss": 0.7196,
      "step": 299500
    },
    {
      "epoch": 3.15,
      "learning_rate": 3.424816491121216e-05,
      "loss": 0.7204,
      "step": 300000
    },
    {
      "epoch": 3.16,
      "learning_rate": 3.4221911852730845e-05,
      "loss": 0.7215,
      "step": 300500
    },
    {
      "epoch": 3.16,
      "learning_rate": 3.419565879424953e-05,
      "loss": 0.7126,
      "step": 301000
    },
    {
      "epoch": 3.17,
      "learning_rate": 3.4169405735768216e-05,
      "loss": 0.7238,
      "step": 301500
    },
    {
      "epoch": 3.17,
      "learning_rate": 3.4143152677286905e-05,
      "loss": 0.7128,
      "step": 302000
    },
    {
      "epoch": 3.18,
      "learning_rate": 3.4116899618805594e-05,
      "loss": 0.7267,
      "step": 302500
    },
    {
      "epoch": 3.18,
      "learning_rate": 3.409064656032428e-05,
      "loss": 0.7244,
      "step": 303000
    },
    {
      "epoch": 3.19,
      "learning_rate": 3.4064393501842965e-05,
      "loss": 0.7287,
      "step": 303500
    },
    {
      "epoch": 3.19,
      "learning_rate": 3.4038140443361654e-05,
      "loss": 0.7152,
      "step": 304000
    },
    {
      "epoch": 3.2,
      "learning_rate": 3.401188738488034e-05,
      "loss": 0.715,
      "step": 304500
    },
    {
      "epoch": 3.2,
      "learning_rate": 3.398563432639903e-05,
      "loss": 0.7205,
      "step": 305000
    },
    {
      "epoch": 3.21,
      "learning_rate": 3.3959381267917714e-05,
      "loss": 0.7214,
      "step": 305500
    },
    {
      "epoch": 3.21,
      "learning_rate": 3.3933128209436396e-05,
      "loss": 0.7148,
      "step": 306000
    },
    {
      "epoch": 3.22,
      "learning_rate": 3.3906875150955085e-05,
      "loss": 0.7135,
      "step": 306500
    },
    {
      "epoch": 3.22,
      "learning_rate": 3.3880622092473774e-05,
      "loss": 0.722,
      "step": 307000
    },
    {
      "epoch": 3.23,
      "learning_rate": 3.385436903399246e-05,
      "loss": 0.7176,
      "step": 307500
    },
    {
      "epoch": 3.23,
      "learning_rate": 3.382811597551115e-05,
      "loss": 0.7153,
      "step": 308000
    },
    {
      "epoch": 3.24,
      "learning_rate": 3.3801862917029834e-05,
      "loss": 0.717,
      "step": 308500
    },
    {
      "epoch": 3.24,
      "learning_rate": 3.377560985854852e-05,
      "loss": 0.7219,
      "step": 309000
    },
    {
      "epoch": 3.25,
      "learning_rate": 3.374935680006721e-05,
      "loss": 0.7079,
      "step": 309500
    },
    {
      "epoch": 3.26,
      "learning_rate": 3.37231037415859e-05,
      "loss": 0.71,
      "step": 310000
    },
    {
      "epoch": 3.26,
      "learning_rate": 3.369685068310458e-05,
      "loss": 0.7037,
      "step": 310500
    },
    {
      "epoch": 3.27,
      "learning_rate": 3.3670597624623265e-05,
      "loss": 0.7122,
      "step": 311000
    },
    {
      "epoch": 3.27,
      "learning_rate": 3.3644344566141954e-05,
      "loss": 0.714,
      "step": 311500
    },
    {
      "epoch": 3.28,
      "learning_rate": 3.361809150766064e-05,
      "loss": 0.7095,
      "step": 312000
    },
    {
      "epoch": 3.28,
      "learning_rate": 3.359183844917933e-05,
      "loss": 0.7047,
      "step": 312500
    },
    {
      "epoch": 3.29,
      "learning_rate": 3.356558539069802e-05,
      "loss": 0.7197,
      "step": 313000
    },
    {
      "epoch": 3.29,
      "learning_rate": 3.35393323322167e-05,
      "loss": 0.7165,
      "step": 313500
    },
    {
      "epoch": 3.3,
      "learning_rate": 3.351307927373539e-05,
      "loss": 0.7185,
      "step": 314000
    },
    {
      "epoch": 3.3,
      "learning_rate": 3.348682621525408e-05,
      "loss": 0.7166,
      "step": 314500
    },
    {
      "epoch": 3.31,
      "learning_rate": 3.346057315677277e-05,
      "loss": 0.7226,
      "step": 315000
    },
    {
      "epoch": 3.31,
      "learning_rate": 3.343432009829145e-05,
      "loss": 0.7092,
      "step": 315500
    },
    {
      "epoch": 3.32,
      "learning_rate": 3.3408067039810134e-05,
      "loss": 0.7161,
      "step": 316000
    },
    {
      "epoch": 3.32,
      "learning_rate": 3.338181398132882e-05,
      "loss": 0.7131,
      "step": 316500
    },
    {
      "epoch": 3.33,
      "learning_rate": 3.335556092284751e-05,
      "loss": 0.6989,
      "step": 317000
    },
    {
      "epoch": 3.33,
      "learning_rate": 3.33293078643662e-05,
      "loss": 0.6974,
      "step": 317500
    },
    {
      "epoch": 3.34,
      "learning_rate": 3.3303054805884883e-05,
      "loss": 0.7069,
      "step": 318000
    },
    {
      "epoch": 3.34,
      "learning_rate": 3.327680174740357e-05,
      "loss": 0.7127,
      "step": 318500
    },
    {
      "epoch": 3.35,
      "learning_rate": 3.325054868892226e-05,
      "loss": 0.7077,
      "step": 319000
    },
    {
      "epoch": 3.36,
      "learning_rate": 3.322429563044095e-05,
      "loss": 0.7121,
      "step": 319500
    },
    {
      "epoch": 3.36,
      "learning_rate": 3.319804257195964e-05,
      "loss": 0.7104,
      "step": 320000
    },
    {
      "epoch": 3.37,
      "learning_rate": 3.317178951347832e-05,
      "loss": 0.7066,
      "step": 320500
    },
    {
      "epoch": 3.37,
      "learning_rate": 3.3145536454997004e-05,
      "loss": 0.7117,
      "step": 321000
    },
    {
      "epoch": 3.38,
      "learning_rate": 3.311928339651569e-05,
      "loss": 0.7032,
      "step": 321500
    },
    {
      "epoch": 3.38,
      "learning_rate": 3.309303033803438e-05,
      "loss": 0.7136,
      "step": 322000
    },
    {
      "epoch": 3.39,
      "learning_rate": 3.306677727955307e-05,
      "loss": 0.7133,
      "step": 322500
    },
    {
      "epoch": 3.39,
      "learning_rate": 3.304052422107175e-05,
      "loss": 0.7087,
      "step": 323000
    },
    {
      "epoch": 3.4,
      "learning_rate": 3.301427116259044e-05,
      "loss": 0.7194,
      "step": 323500
    },
    {
      "epoch": 3.4,
      "learning_rate": 3.298801810410913e-05,
      "loss": 0.7046,
      "step": 324000
    },
    {
      "epoch": 3.41,
      "learning_rate": 3.296176504562782e-05,
      "loss": 0.7072,
      "step": 324500
    },
    {
      "epoch": 3.41,
      "learning_rate": 3.293551198714651e-05,
      "loss": 0.7071,
      "step": 325000
    },
    {
      "epoch": 3.42,
      "learning_rate": 3.290925892866519e-05,
      "loss": 0.7043,
      "step": 325500
    },
    {
      "epoch": 3.42,
      "learning_rate": 3.288300587018388e-05,
      "loss": 0.6983,
      "step": 326000
    },
    {
      "epoch": 3.43,
      "learning_rate": 3.285675281170256e-05,
      "loss": 0.7018,
      "step": 326500
    },
    {
      "epoch": 3.43,
      "learning_rate": 3.283049975322125e-05,
      "loss": 0.7122,
      "step": 327000
    },
    {
      "epoch": 3.44,
      "learning_rate": 3.280424669473994e-05,
      "loss": 0.7022,
      "step": 327500
    },
    {
      "epoch": 3.44,
      "learning_rate": 3.277799363625862e-05,
      "loss": 0.705,
      "step": 328000
    },
    {
      "epoch": 3.45,
      "learning_rate": 3.275174057777731e-05,
      "loss": 0.7041,
      "step": 328500
    },
    {
      "epoch": 3.45,
      "learning_rate": 3.2725487519296e-05,
      "loss": 0.692,
      "step": 329000
    },
    {
      "epoch": 3.46,
      "learning_rate": 3.269923446081469e-05,
      "loss": 0.7056,
      "step": 329500
    },
    {
      "epoch": 3.47,
      "learning_rate": 3.267298140233338e-05,
      "loss": 0.6959,
      "step": 330000
    },
    {
      "epoch": 3.47,
      "learning_rate": 3.264672834385206e-05,
      "loss": 0.6994,
      "step": 330500
    },
    {
      "epoch": 3.48,
      "learning_rate": 3.262047528537075e-05,
      "loss": 0.703,
      "step": 331000
    },
    {
      "epoch": 3.48,
      "learning_rate": 3.259422222688943e-05,
      "loss": 0.7032,
      "step": 331500
    },
    {
      "epoch": 3.49,
      "learning_rate": 3.256796916840812e-05,
      "loss": 0.6984,
      "step": 332000
    },
    {
      "epoch": 3.49,
      "learning_rate": 3.254171610992681e-05,
      "loss": 0.701,
      "step": 332500
    },
    {
      "epoch": 3.5,
      "learning_rate": 3.251546305144549e-05,
      "loss": 0.6885,
      "step": 333000
    },
    {
      "epoch": 3.5,
      "learning_rate": 3.248920999296418e-05,
      "loss": 0.7005,
      "step": 333500
    },
    {
      "epoch": 3.51,
      "learning_rate": 3.246295693448287e-05,
      "loss": 0.6972,
      "step": 334000
    },
    {
      "epoch": 3.51,
      "learning_rate": 3.243670387600156e-05,
      "loss": 0.7018,
      "step": 334500
    },
    {
      "epoch": 3.52,
      "learning_rate": 3.2410450817520247e-05,
      "loss": 0.6953,
      "step": 335000
    },
    {
      "epoch": 3.52,
      "learning_rate": 3.238419775903893e-05,
      "loss": 0.6979,
      "step": 335500
    },
    {
      "epoch": 3.53,
      "learning_rate": 3.235794470055762e-05,
      "loss": 0.6968,
      "step": 336000
    },
    {
      "epoch": 3.53,
      "learning_rate": 3.2331691642076307e-05,
      "loss": 0.6928,
      "step": 336500
    },
    {
      "epoch": 3.54,
      "learning_rate": 3.230543858359499e-05,
      "loss": 0.7043,
      "step": 337000
    },
    {
      "epoch": 3.54,
      "learning_rate": 3.227918552511368e-05,
      "loss": 0.6981,
      "step": 337500
    },
    {
      "epoch": 3.55,
      "learning_rate": 3.225293246663236e-05,
      "loss": 0.6939,
      "step": 338000
    },
    {
      "epoch": 3.55,
      "learning_rate": 3.222667940815105e-05,
      "loss": 0.6884,
      "step": 338500
    },
    {
      "epoch": 3.56,
      "learning_rate": 3.220042634966974e-05,
      "loss": 0.7009,
      "step": 339000
    },
    {
      "epoch": 3.57,
      "learning_rate": 3.217417329118843e-05,
      "loss": 0.6963,
      "step": 339500
    },
    {
      "epoch": 3.57,
      "learning_rate": 3.2147920232707116e-05,
      "loss": 0.6962,
      "step": 340000
    },
    {
      "epoch": 3.58,
      "learning_rate": 3.21216671742258e-05,
      "loss": 0.7024,
      "step": 340500
    },
    {
      "epoch": 3.58,
      "learning_rate": 3.209541411574449e-05,
      "loss": 0.6874,
      "step": 341000
    },
    {
      "epoch": 3.59,
      "learning_rate": 3.2069161057263176e-05,
      "loss": 0.701,
      "step": 341500
    },
    {
      "epoch": 3.59,
      "learning_rate": 3.204290799878186e-05,
      "loss": 0.6928,
      "step": 342000
    },
    {
      "epoch": 3.6,
      "learning_rate": 3.201665494030055e-05,
      "loss": 0.6877,
      "step": 342500
    },
    {
      "epoch": 3.6,
      "learning_rate": 3.199040188181923e-05,
      "loss": 0.691,
      "step": 343000
    },
    {
      "epoch": 3.61,
      "learning_rate": 3.196414882333792e-05,
      "loss": 0.6923,
      "step": 343500
    },
    {
      "epoch": 3.61,
      "learning_rate": 3.193789576485661e-05,
      "loss": 0.6999,
      "step": 344000
    },
    {
      "epoch": 3.62,
      "learning_rate": 3.1911642706375296e-05,
      "loss": 0.6928,
      "step": 344500
    },
    {
      "epoch": 3.62,
      "learning_rate": 3.1885389647893985e-05,
      "loss": 0.6892,
      "step": 345000
    },
    {
      "epoch": 3.63,
      "learning_rate": 3.185913658941267e-05,
      "loss": 0.6949,
      "step": 345500
    },
    {
      "epoch": 3.63,
      "learning_rate": 3.1832883530931356e-05,
      "loss": 0.6814,
      "step": 346000
    },
    {
      "epoch": 3.64,
      "learning_rate": 3.1806630472450045e-05,
      "loss": 0.6865,
      "step": 346500
    },
    {
      "epoch": 3.64,
      "learning_rate": 3.1780377413968734e-05,
      "loss": 0.697,
      "step": 347000
    },
    {
      "epoch": 3.65,
      "learning_rate": 3.1754124355487416e-05,
      "loss": 0.6876,
      "step": 347500
    },
    {
      "epoch": 3.65,
      "learning_rate": 3.17278712970061e-05,
      "loss": 0.6895,
      "step": 348000
    },
    {
      "epoch": 3.66,
      "learning_rate": 3.170161823852479e-05,
      "loss": 0.6978,
      "step": 348500
    },
    {
      "epoch": 3.66,
      "learning_rate": 3.1675365180043476e-05,
      "loss": 0.6869,
      "step": 349000
    },
    {
      "epoch": 3.67,
      "learning_rate": 3.1649112121562165e-05,
      "loss": 0.6958,
      "step": 349500
    },
    {
      "epoch": 3.68,
      "learning_rate": 3.1622859063080854e-05,
      "loss": 0.6936,
      "step": 350000
    },
    {
      "epoch": 3.68,
      "learning_rate": 3.1596606004599536e-05,
      "loss": 0.6823,
      "step": 350500
    },
    {
      "epoch": 3.69,
      "learning_rate": 3.1570352946118225e-05,
      "loss": 0.6856,
      "step": 351000
    },
    {
      "epoch": 3.69,
      "learning_rate": 3.1544099887636914e-05,
      "loss": 0.6923,
      "step": 351500
    },
    {
      "epoch": 3.7,
      "learning_rate": 3.15178468291556e-05,
      "loss": 0.6868,
      "step": 352000
    },
    {
      "epoch": 3.7,
      "learning_rate": 3.1491593770674285e-05,
      "loss": 0.6927,
      "step": 352500
    },
    {
      "epoch": 3.71,
      "learning_rate": 3.146534071219297e-05,
      "loss": 0.6813,
      "step": 353000
    },
    {
      "epoch": 3.71,
      "learning_rate": 3.1439087653711656e-05,
      "loss": 0.6845,
      "step": 353500
    },
    {
      "epoch": 3.72,
      "learning_rate": 3.1412834595230345e-05,
      "loss": 0.6826,
      "step": 354000
    },
    {
      "epoch": 3.72,
      "learning_rate": 3.1386581536749034e-05,
      "loss": 0.6846,
      "step": 354500
    },
    {
      "epoch": 3.73,
      "learning_rate": 3.136032847826772e-05,
      "loss": 0.6838,
      "step": 355000
    },
    {
      "epoch": 3.73,
      "learning_rate": 3.1334075419786405e-05,
      "loss": 0.6935,
      "step": 355500
    },
    {
      "epoch": 3.74,
      "learning_rate": 3.1307822361305094e-05,
      "loss": 0.6878,
      "step": 356000
    },
    {
      "epoch": 3.74,
      "learning_rate": 3.128156930282378e-05,
      "loss": 0.6741,
      "step": 356500
    },
    {
      "epoch": 3.75,
      "learning_rate": 3.125531624434247e-05,
      "loss": 0.6863,
      "step": 357000
    },
    {
      "epoch": 3.75,
      "learning_rate": 3.1229063185861154e-05,
      "loss": 0.6931,
      "step": 357500
    },
    {
      "epoch": 3.76,
      "learning_rate": 3.1202810127379836e-05,
      "loss": 0.6928,
      "step": 358000
    },
    {
      "epoch": 3.76,
      "learning_rate": 3.1176557068898525e-05,
      "loss": 0.69,
      "step": 358500
    },
    {
      "epoch": 3.77,
      "learning_rate": 3.1150304010417214e-05,
      "loss": 0.6834,
      "step": 359000
    },
    {
      "epoch": 3.78,
      "learning_rate": 3.11240509519359e-05,
      "loss": 0.6856,
      "step": 359500
    },
    {
      "epoch": 3.78,
      "learning_rate": 3.109779789345459e-05,
      "loss": 0.6927,
      "step": 360000
    },
    {
      "epoch": 3.79,
      "learning_rate": 3.1071544834973274e-05,
      "loss": 0.6888,
      "step": 360500
    },
    {
      "epoch": 3.79,
      "learning_rate": 3.104529177649196e-05,
      "loss": 0.6817,
      "step": 361000
    },
    {
      "epoch": 3.8,
      "learning_rate": 3.101903871801065e-05,
      "loss": 0.6768,
      "step": 361500
    },
    {
      "epoch": 3.8,
      "learning_rate": 3.099278565952934e-05,
      "loss": 0.6773,
      "step": 362000
    },
    {
      "epoch": 3.81,
      "learning_rate": 3.096653260104802e-05,
      "loss": 0.6808,
      "step": 362500
    },
    {
      "epoch": 3.81,
      "learning_rate": 3.0940279542566705e-05,
      "loss": 0.6803,
      "step": 363000
    },
    {
      "epoch": 3.82,
      "learning_rate": 3.0914026484085394e-05,
      "loss": 0.6879,
      "step": 363500
    },
    {
      "epoch": 3.82,
      "learning_rate": 3.088777342560408e-05,
      "loss": 0.6886,
      "step": 364000
    },
    {
      "epoch": 3.83,
      "learning_rate": 3.086152036712277e-05,
      "loss": 0.6816,
      "step": 364500
    },
    {
      "epoch": 3.83,
      "learning_rate": 3.083526730864146e-05,
      "loss": 0.6851,
      "step": 365000
    },
    {
      "epoch": 3.84,
      "learning_rate": 3.080901425016014e-05,
      "loss": 0.6765,
      "step": 365500
    },
    {
      "epoch": 3.84,
      "learning_rate": 3.078276119167883e-05,
      "loss": 0.6788,
      "step": 366000
    },
    {
      "epoch": 3.85,
      "learning_rate": 3.075650813319752e-05,
      "loss": 0.683,
      "step": 366500
    },
    {
      "epoch": 3.85,
      "learning_rate": 3.073025507471621e-05,
      "loss": 0.6751,
      "step": 367000
    },
    {
      "epoch": 3.86,
      "learning_rate": 3.070400201623489e-05,
      "loss": 0.6836,
      "step": 367500
    },
    {
      "epoch": 3.86,
      "learning_rate": 3.0677748957753575e-05,
      "loss": 0.6772,
      "step": 368000
    },
    {
      "epoch": 3.87,
      "learning_rate": 3.0651495899272263e-05,
      "loss": 0.6781,
      "step": 368500
    },
    {
      "epoch": 3.87,
      "learning_rate": 3.062524284079095e-05,
      "loss": 0.6742,
      "step": 369000
    },
    {
      "epoch": 3.88,
      "learning_rate": 3.059898978230964e-05,
      "loss": 0.6774,
      "step": 369500
    },
    {
      "epoch": 3.89,
      "learning_rate": 3.0572736723828324e-05,
      "loss": 0.6717,
      "step": 370000
    },
    {
      "epoch": 3.89,
      "learning_rate": 3.054648366534701e-05,
      "loss": 0.677,
      "step": 370500
    },
    {
      "epoch": 3.9,
      "learning_rate": 3.05202306068657e-05,
      "loss": 0.6835,
      "step": 371000
    },
    {
      "epoch": 3.9,
      "learning_rate": 3.049397754838439e-05,
      "loss": 0.6678,
      "step": 371500
    },
    {
      "epoch": 3.91,
      "learning_rate": 3.0467724489903076e-05,
      "loss": 0.6717,
      "step": 372000
    },
    {
      "epoch": 3.91,
      "learning_rate": 3.0441471431421765e-05,
      "loss": 0.6809,
      "step": 372500
    },
    {
      "epoch": 3.92,
      "learning_rate": 3.041521837294045e-05,
      "loss": 0.6774,
      "step": 373000
    },
    {
      "epoch": 3.92,
      "learning_rate": 3.0388965314459133e-05,
      "loss": 0.677,
      "step": 373500
    },
    {
      "epoch": 3.93,
      "learning_rate": 3.036271225597782e-05,
      "loss": 0.6758,
      "step": 374000
    },
    {
      "epoch": 3.93,
      "learning_rate": 3.0336459197496507e-05,
      "loss": 0.6716,
      "step": 374500
    },
    {
      "epoch": 3.94,
      "learning_rate": 3.0310206139015196e-05,
      "loss": 0.6675,
      "step": 375000
    },
    {
      "epoch": 3.94,
      "learning_rate": 3.0283953080533885e-05,
      "loss": 0.6862,
      "step": 375500
    },
    {
      "epoch": 3.95,
      "learning_rate": 3.025770002205257e-05,
      "loss": 0.6748,
      "step": 376000
    },
    {
      "epoch": 3.95,
      "learning_rate": 3.023144696357126e-05,
      "loss": 0.6637,
      "step": 376500
    },
    {
      "epoch": 3.96,
      "learning_rate": 3.0205193905089945e-05,
      "loss": 0.6726,
      "step": 377000
    },
    {
      "epoch": 3.96,
      "learning_rate": 3.0178940846608634e-05,
      "loss": 0.6752,
      "step": 377500
    },
    {
      "epoch": 3.97,
      "learning_rate": 3.015268778812732e-05,
      "loss": 0.6748,
      "step": 378000
    },
    {
      "epoch": 3.97,
      "learning_rate": 3.0126434729646002e-05,
      "loss": 0.6679,
      "step": 378500
    },
    {
      "epoch": 3.98,
      "learning_rate": 3.010018167116469e-05,
      "loss": 0.6665,
      "step": 379000
    },
    {
      "epoch": 3.99,
      "learning_rate": 3.0073928612683376e-05,
      "loss": 0.6772,
      "step": 379500
    },
    {
      "epoch": 3.99,
      "learning_rate": 3.0047675554202065e-05,
      "loss": 0.6787,
      "step": 380000
    },
    {
      "epoch": 4.0,
      "learning_rate": 3.002142249572075e-05,
      "loss": 0.6751,
      "step": 380500
    },
    {
      "epoch": 4.0,
      "learning_rate": 2.999516943723944e-05,
      "loss": 0.6645,
      "step": 381000
    },
    {
      "epoch": 4.01,
      "learning_rate": 2.996891637875813e-05,
      "loss": 0.6683,
      "step": 381500
    },
    {
      "epoch": 4.01,
      "learning_rate": 2.9942663320276814e-05,
      "loss": 0.6627,
      "step": 382000
    },
    {
      "epoch": 4.02,
      "learning_rate": 2.9916410261795503e-05,
      "loss": 0.6741,
      "step": 382500
    },
    {
      "epoch": 4.02,
      "learning_rate": 2.989015720331419e-05,
      "loss": 0.6678,
      "step": 383000
    },
    {
      "epoch": 4.03,
      "learning_rate": 2.9863904144832878e-05,
      "loss": 0.6662,
      "step": 383500
    },
    {
      "epoch": 4.03,
      "learning_rate": 2.983765108635156e-05,
      "loss": 0.663,
      "step": 384000
    },
    {
      "epoch": 4.04,
      "learning_rate": 2.9811398027870245e-05,
      "loss": 0.6633,
      "step": 384500
    },
    {
      "epoch": 4.04,
      "learning_rate": 2.9785144969388934e-05,
      "loss": 0.6692,
      "step": 385000
    },
    {
      "epoch": 4.05,
      "learning_rate": 2.975889191090762e-05,
      "loss": 0.6627,
      "step": 385500
    },
    {
      "epoch": 4.05,
      "learning_rate": 2.973263885242631e-05,
      "loss": 0.6603,
      "step": 386000
    },
    {
      "epoch": 4.06,
      "learning_rate": 2.9706385793944998e-05,
      "loss": 0.664,
      "step": 386500
    },
    {
      "epoch": 4.06,
      "learning_rate": 2.9680132735463683e-05,
      "loss": 0.6631,
      "step": 387000
    },
    {
      "epoch": 4.07,
      "learning_rate": 2.9653879676982372e-05,
      "loss": 0.6653,
      "step": 387500
    },
    {
      "epoch": 4.07,
      "learning_rate": 2.9627626618501058e-05,
      "loss": 0.6566,
      "step": 388000
    },
    {
      "epoch": 4.08,
      "learning_rate": 2.9601373560019747e-05,
      "loss": 0.6611,
      "step": 388500
    },
    {
      "epoch": 4.08,
      "learning_rate": 2.957512050153843e-05,
      "loss": 0.6525,
      "step": 389000
    },
    {
      "epoch": 4.09,
      "learning_rate": 2.9548867443057114e-05,
      "loss": 0.6637,
      "step": 389500
    },
    {
      "epoch": 4.1,
      "learning_rate": 2.9522614384575803e-05,
      "loss": 0.6605,
      "step": 390000
    },
    {
      "epoch": 4.1,
      "learning_rate": 2.949636132609449e-05,
      "loss": 0.6646,
      "step": 390500
    },
    {
      "epoch": 4.11,
      "learning_rate": 2.9470108267613178e-05,
      "loss": 0.6613,
      "step": 391000
    },
    {
      "epoch": 4.11,
      "learning_rate": 2.9443855209131867e-05,
      "loss": 0.6652,
      "step": 391500
    },
    {
      "epoch": 4.12,
      "learning_rate": 2.9417602150650552e-05,
      "loss": 0.6582,
      "step": 392000
    },
    {
      "epoch": 4.12,
      "learning_rate": 2.939134909216924e-05,
      "loss": 0.671,
      "step": 392500
    },
    {
      "epoch": 4.13,
      "learning_rate": 2.9365096033687927e-05,
      "loss": 0.662,
      "step": 393000
    },
    {
      "epoch": 4.13,
      "learning_rate": 2.9338842975206616e-05,
      "loss": 0.6588,
      "step": 393500
    },
    {
      "epoch": 4.14,
      "learning_rate": 2.93125899167253e-05,
      "loss": 0.6692,
      "step": 394000
    },
    {
      "epoch": 4.14,
      "learning_rate": 2.9286336858243984e-05,
      "loss": 0.6516,
      "step": 394500
    },
    {
      "epoch": 4.15,
      "learning_rate": 2.9260083799762673e-05,
      "loss": 0.668,
      "step": 395000
    },
    {
      "epoch": 4.15,
      "learning_rate": 2.9233830741281358e-05,
      "loss": 0.6618,
      "step": 395500
    },
    {
      "epoch": 4.16,
      "learning_rate": 2.9207577682800047e-05,
      "loss": 0.6571,
      "step": 396000
    },
    {
      "epoch": 4.16,
      "learning_rate": 2.9181324624318736e-05,
      "loss": 0.6625,
      "step": 396500
    },
    {
      "epoch": 4.17,
      "learning_rate": 2.915507156583742e-05,
      "loss": 0.6553,
      "step": 397000
    },
    {
      "epoch": 4.17,
      "learning_rate": 2.912881850735611e-05,
      "loss": 0.6682,
      "step": 397500
    },
    {
      "epoch": 4.18,
      "learning_rate": 2.9102565448874796e-05,
      "loss": 0.6644,
      "step": 398000
    },
    {
      "epoch": 4.18,
      "learning_rate": 2.9076312390393485e-05,
      "loss": 0.6515,
      "step": 398500
    },
    {
      "epoch": 4.19,
      "learning_rate": 2.905005933191217e-05,
      "loss": 0.6597,
      "step": 399000
    },
    {
      "epoch": 4.2,
      "learning_rate": 2.9023806273430853e-05,
      "loss": 0.6564,
      "step": 399500
    },
    {
      "epoch": 4.2,
      "learning_rate": 2.899755321494954e-05,
      "loss": 0.6539,
      "step": 400000
    },
    {
      "epoch": 4.21,
      "learning_rate": 2.8971300156468227e-05,
      "loss": 0.6593,
      "step": 400500
    },
    {
      "epoch": 4.21,
      "learning_rate": 2.8945047097986916e-05,
      "loss": 0.6596,
      "step": 401000
    },
    {
      "epoch": 4.22,
      "learning_rate": 2.8918794039505605e-05,
      "loss": 0.658,
      "step": 401500
    },
    {
      "epoch": 4.22,
      "learning_rate": 2.889254098102429e-05,
      "loss": 0.6495,
      "step": 402000
    },
    {
      "epoch": 4.23,
      "learning_rate": 2.886628792254298e-05,
      "loss": 0.654,
      "step": 402500
    },
    {
      "epoch": 4.23,
      "learning_rate": 2.8840034864061665e-05,
      "loss": 0.6601,
      "step": 403000
    },
    {
      "epoch": 4.24,
      "learning_rate": 2.8813781805580354e-05,
      "loss": 0.6545,
      "step": 403500
    },
    {
      "epoch": 4.24,
      "learning_rate": 2.878752874709904e-05,
      "loss": 0.6662,
      "step": 404000
    },
    {
      "epoch": 4.25,
      "learning_rate": 2.8761275688617722e-05,
      "loss": 0.6531,
      "step": 404500
    },
    {
      "epoch": 4.25,
      "learning_rate": 2.873502263013641e-05,
      "loss": 0.6533,
      "step": 405000
    },
    {
      "epoch": 4.26,
      "learning_rate": 2.8708769571655096e-05,
      "loss": 0.6544,
      "step": 405500
    },
    {
      "epoch": 4.26,
      "learning_rate": 2.8682516513173785e-05,
      "loss": 0.6643,
      "step": 406000
    },
    {
      "epoch": 4.27,
      "learning_rate": 2.865626345469247e-05,
      "loss": 0.6543,
      "step": 406500
    },
    {
      "epoch": 4.27,
      "learning_rate": 2.863001039621116e-05,
      "loss": 0.6544,
      "step": 407000
    },
    {
      "epoch": 4.28,
      "learning_rate": 2.860375733772985e-05,
      "loss": 0.6593,
      "step": 407500
    },
    {
      "epoch": 4.28,
      "learning_rate": 2.8577504279248534e-05,
      "loss": 0.6511,
      "step": 408000
    },
    {
      "epoch": 4.29,
      "learning_rate": 2.8551251220767223e-05,
      "loss": 0.6464,
      "step": 408500
    },
    {
      "epoch": 4.3,
      "learning_rate": 2.852499816228591e-05,
      "loss": 0.6558,
      "step": 409000
    },
    {
      "epoch": 4.3,
      "learning_rate": 2.8498745103804598e-05,
      "loss": 0.646,
      "step": 409500
    },
    {
      "epoch": 4.31,
      "learning_rate": 2.847249204532328e-05,
      "loss": 0.6537,
      "step": 410000
    },
    {
      "epoch": 4.31,
      "learning_rate": 2.8446238986841965e-05,
      "loss": 0.6468,
      "step": 410500
    },
    {
      "epoch": 4.32,
      "learning_rate": 2.8419985928360654e-05,
      "loss": 0.6523,
      "step": 411000
    },
    {
      "epoch": 4.32,
      "learning_rate": 2.839373286987934e-05,
      "loss": 0.65,
      "step": 411500
    },
    {
      "epoch": 4.33,
      "learning_rate": 2.836747981139803e-05,
      "loss": 0.6454,
      "step": 412000
    },
    {
      "epoch": 4.33,
      "learning_rate": 2.8341226752916718e-05,
      "loss": 0.6526,
      "step": 412500
    },
    {
      "epoch": 4.34,
      "learning_rate": 2.8314973694435403e-05,
      "loss": 0.6404,
      "step": 413000
    },
    {
      "epoch": 4.34,
      "learning_rate": 2.8288720635954092e-05,
      "loss": 0.6546,
      "step": 413500
    },
    {
      "epoch": 4.35,
      "learning_rate": 2.8262467577472778e-05,
      "loss": 0.6464,
      "step": 414000
    },
    {
      "epoch": 4.35,
      "learning_rate": 2.8236214518991467e-05,
      "loss": 0.648,
      "step": 414500
    },
    {
      "epoch": 4.36,
      "learning_rate": 2.820996146051015e-05,
      "loss": 0.6443,
      "step": 415000
    },
    {
      "epoch": 4.36,
      "learning_rate": 2.8183708402028835e-05,
      "loss": 0.6536,
      "step": 415500
    },
    {
      "epoch": 4.37,
      "learning_rate": 2.8157455343547523e-05,
      "loss": 0.6439,
      "step": 416000
    },
    {
      "epoch": 4.37,
      "learning_rate": 2.813120228506621e-05,
      "loss": 0.6481,
      "step": 416500
    },
    {
      "epoch": 4.38,
      "learning_rate": 2.8104949226584898e-05,
      "loss": 0.6535,
      "step": 417000
    },
    {
      "epoch": 4.38,
      "learning_rate": 2.8078696168103587e-05,
      "loss": 0.6437,
      "step": 417500
    },
    {
      "epoch": 4.39,
      "learning_rate": 2.8052443109622272e-05,
      "loss": 0.6434,
      "step": 418000
    },
    {
      "epoch": 4.39,
      "learning_rate": 2.802619005114096e-05,
      "loss": 0.6464,
      "step": 418500
    },
    {
      "epoch": 4.4,
      "learning_rate": 2.7999936992659647e-05,
      "loss": 0.6424,
      "step": 419000
    },
    {
      "epoch": 4.41,
      "learning_rate": 2.7973683934178336e-05,
      "loss": 0.649,
      "step": 419500
    },
    {
      "epoch": 4.41,
      "learning_rate": 2.794743087569702e-05,
      "loss": 0.6484,
      "step": 420000
    },
    {
      "epoch": 4.42,
      "learning_rate": 2.7921177817215704e-05,
      "loss": 0.652,
      "step": 420500
    },
    {
      "epoch": 4.42,
      "learning_rate": 2.7894924758734393e-05,
      "loss": 0.6494,
      "step": 421000
    },
    {
      "epoch": 4.43,
      "learning_rate": 2.7868671700253078e-05,
      "loss": 0.6534,
      "step": 421500
    },
    {
      "epoch": 4.43,
      "learning_rate": 2.7842418641771767e-05,
      "loss": 0.6462,
      "step": 422000
    },
    {
      "epoch": 4.44,
      "learning_rate": 2.7816165583290456e-05,
      "loss": 0.6548,
      "step": 422500
    },
    {
      "epoch": 4.44,
      "learning_rate": 2.778991252480914e-05,
      "loss": 0.6399,
      "step": 423000
    },
    {
      "epoch": 4.45,
      "learning_rate": 2.776365946632783e-05,
      "loss": 0.6404,
      "step": 423500
    },
    {
      "epoch": 4.45,
      "learning_rate": 2.7737406407846516e-05,
      "loss": 0.6434,
      "step": 424000
    },
    {
      "epoch": 4.46,
      "learning_rate": 2.7711153349365205e-05,
      "loss": 0.6394,
      "step": 424500
    },
    {
      "epoch": 4.46,
      "learning_rate": 2.768490029088389e-05,
      "loss": 0.6469,
      "step": 425000
    },
    {
      "epoch": 4.47,
      "learning_rate": 2.7658647232402573e-05,
      "loss": 0.6404,
      "step": 425500
    },
    {
      "epoch": 4.47,
      "learning_rate": 2.763239417392126e-05,
      "loss": 0.6378,
      "step": 426000
    },
    {
      "epoch": 4.48,
      "learning_rate": 2.7606141115439947e-05,
      "loss": 0.6512,
      "step": 426500
    },
    {
      "epoch": 4.48,
      "learning_rate": 2.7579888056958636e-05,
      "loss": 0.6428,
      "step": 427000
    },
    {
      "epoch": 4.49,
      "learning_rate": 2.7553634998477325e-05,
      "loss": 0.6453,
      "step": 427500
    },
    {
      "epoch": 4.49,
      "learning_rate": 2.752738193999601e-05,
      "loss": 0.6441,
      "step": 428000
    },
    {
      "epoch": 4.5,
      "learning_rate": 2.75011288815147e-05,
      "loss": 0.6365,
      "step": 428500
    },
    {
      "epoch": 4.51,
      "learning_rate": 2.7474875823033385e-05,
      "loss": 0.6396,
      "step": 429000
    },
    {
      "epoch": 4.51,
      "learning_rate": 2.7448622764552074e-05,
      "loss": 0.6442,
      "step": 429500
    },
    {
      "epoch": 4.52,
      "learning_rate": 2.742236970607076e-05,
      "loss": 0.643,
      "step": 430000
    },
    {
      "epoch": 4.52,
      "learning_rate": 2.739611664758945e-05,
      "loss": 0.6436,
      "step": 430500
    },
    {
      "epoch": 4.53,
      "learning_rate": 2.736986358910813e-05,
      "loss": 0.6428,
      "step": 431000
    },
    {
      "epoch": 4.53,
      "learning_rate": 2.7343610530626816e-05,
      "loss": 0.6508,
      "step": 431500
    },
    {
      "epoch": 4.54,
      "learning_rate": 2.7317357472145505e-05,
      "loss": 0.638,
      "step": 432000
    },
    {
      "epoch": 4.54,
      "learning_rate": 2.729110441366419e-05,
      "loss": 0.6488,
      "step": 432500
    },
    {
      "epoch": 4.55,
      "learning_rate": 2.726485135518288e-05,
      "loss": 0.6462,
      "step": 433000
    },
    {
      "epoch": 4.55,
      "learning_rate": 2.723859829670157e-05,
      "loss": 0.643,
      "step": 433500
    },
    {
      "epoch": 4.56,
      "learning_rate": 2.7212345238220254e-05,
      "loss": 0.6366,
      "step": 434000
    },
    {
      "epoch": 4.56,
      "learning_rate": 2.7186092179738943e-05,
      "loss": 0.6406,
      "step": 434500
    },
    {
      "epoch": 4.57,
      "learning_rate": 2.715983912125763e-05,
      "loss": 0.6476,
      "step": 435000
    },
    {
      "epoch": 4.57,
      "learning_rate": 2.7133586062776318e-05,
      "loss": 0.6386,
      "step": 435500
    },
    {
      "epoch": 4.58,
      "learning_rate": 2.7107333004295e-05,
      "loss": 0.6384,
      "step": 436000
    },
    {
      "epoch": 4.58,
      "learning_rate": 2.7081079945813685e-05,
      "loss": 0.6443,
      "step": 436500
    },
    {
      "epoch": 4.59,
      "learning_rate": 2.7054826887332374e-05,
      "loss": 0.6399,
      "step": 437000
    },
    {
      "epoch": 4.59,
      "learning_rate": 2.702857382885106e-05,
      "loss": 0.6435,
      "step": 437500
    },
    {
      "epoch": 4.6,
      "learning_rate": 2.700232077036975e-05,
      "loss": 0.6394,
      "step": 438000
    },
    {
      "epoch": 4.6,
      "learning_rate": 2.6976067711888438e-05,
      "loss": 0.6428,
      "step": 438500
    },
    {
      "epoch": 4.61,
      "learning_rate": 2.6949814653407123e-05,
      "loss": 0.6386,
      "step": 439000
    },
    {
      "epoch": 4.62,
      "learning_rate": 2.6923561594925812e-05,
      "loss": 0.6386,
      "step": 439500
    },
    {
      "epoch": 4.62,
      "learning_rate": 2.6897308536444498e-05,
      "loss": 0.6371,
      "step": 440000
    },
    {
      "epoch": 4.63,
      "learning_rate": 2.6871055477963187e-05,
      "loss": 0.6433,
      "step": 440500
    },
    {
      "epoch": 4.63,
      "learning_rate": 2.6844802419481872e-05,
      "loss": 0.6451,
      "step": 441000
    },
    {
      "epoch": 4.64,
      "learning_rate": 2.6818549361000555e-05,
      "loss": 0.6382,
      "step": 441500
    },
    {
      "epoch": 4.64,
      "learning_rate": 2.6792296302519244e-05,
      "loss": 0.6337,
      "step": 442000
    },
    {
      "epoch": 4.65,
      "learning_rate": 2.676604324403793e-05,
      "loss": 0.6368,
      "step": 442500
    },
    {
      "epoch": 4.65,
      "learning_rate": 2.6739790185556618e-05,
      "loss": 0.6335,
      "step": 443000
    },
    {
      "epoch": 4.66,
      "learning_rate": 2.6713537127075307e-05,
      "loss": 0.6358,
      "step": 443500
    },
    {
      "epoch": 4.66,
      "learning_rate": 2.6687284068593993e-05,
      "loss": 0.6372,
      "step": 444000
    },
    {
      "epoch": 4.67,
      "learning_rate": 2.666103101011268e-05,
      "loss": 0.6387,
      "step": 444500
    },
    {
      "epoch": 4.67,
      "learning_rate": 2.6634777951631367e-05,
      "loss": 0.6454,
      "step": 445000
    },
    {
      "epoch": 4.68,
      "learning_rate": 2.6608524893150056e-05,
      "loss": 0.6329,
      "step": 445500
    },
    {
      "epoch": 4.68,
      "learning_rate": 2.658227183466874e-05,
      "loss": 0.629,
      "step": 446000
    },
    {
      "epoch": 4.69,
      "learning_rate": 2.6556018776187424e-05,
      "loss": 0.6354,
      "step": 446500
    },
    {
      "epoch": 4.69,
      "learning_rate": 2.6529765717706113e-05,
      "loss": 0.6345,
      "step": 447000
    },
    {
      "epoch": 4.7,
      "learning_rate": 2.6503512659224798e-05,
      "loss": 0.6384,
      "step": 447500
    },
    {
      "epoch": 4.7,
      "learning_rate": 2.6477259600743487e-05,
      "loss": 0.6295,
      "step": 448000
    },
    {
      "epoch": 4.71,
      "learning_rate": 2.6451006542262176e-05,
      "loss": 0.6349,
      "step": 448500
    },
    {
      "epoch": 4.72,
      "learning_rate": 2.642475348378086e-05,
      "loss": 0.6379,
      "step": 449000
    },
    {
      "epoch": 4.72,
      "learning_rate": 2.639850042529955e-05,
      "loss": 0.6355,
      "step": 449500
    },
    {
      "epoch": 4.73,
      "learning_rate": 2.6372247366818236e-05,
      "loss": 0.6444,
      "step": 450000
    },
    {
      "epoch": 4.73,
      "learning_rate": 2.6345994308336925e-05,
      "loss": 0.6376,
      "step": 450500
    },
    {
      "epoch": 4.74,
      "learning_rate": 2.631974124985561e-05,
      "loss": 0.637,
      "step": 451000
    },
    {
      "epoch": 4.74,
      "learning_rate": 2.6293488191374293e-05,
      "loss": 0.6325,
      "step": 451500
    },
    {
      "epoch": 4.75,
      "learning_rate": 2.6267235132892982e-05,
      "loss": 0.6398,
      "step": 452000
    },
    {
      "epoch": 4.75,
      "learning_rate": 2.6240982074411667e-05,
      "loss": 0.6341,
      "step": 452500
    },
    {
      "epoch": 4.76,
      "learning_rate": 2.6214729015930356e-05,
      "loss": 0.6362,
      "step": 453000
    },
    {
      "epoch": 4.76,
      "learning_rate": 2.6188475957449042e-05,
      "loss": 0.6298,
      "step": 453500
    },
    {
      "epoch": 4.77,
      "learning_rate": 2.616222289896773e-05,
      "loss": 0.6483,
      "step": 454000
    },
    {
      "epoch": 4.77,
      "learning_rate": 2.613596984048642e-05,
      "loss": 0.635,
      "step": 454500
    },
    {
      "epoch": 4.78,
      "learning_rate": 2.6109716782005105e-05,
      "loss": 0.6361,
      "step": 455000
    },
    {
      "epoch": 4.78,
      "learning_rate": 2.6083463723523794e-05,
      "loss": 0.6281,
      "step": 455500
    },
    {
      "epoch": 4.79,
      "learning_rate": 2.605721066504248e-05,
      "loss": 0.6276,
      "step": 456000
    },
    {
      "epoch": 4.79,
      "learning_rate": 2.603095760656117e-05,
      "loss": 0.6274,
      "step": 456500
    },
    {
      "epoch": 4.8,
      "learning_rate": 2.600470454807985e-05,
      "loss": 0.6306,
      "step": 457000
    },
    {
      "epoch": 4.8,
      "learning_rate": 2.5978451489598536e-05,
      "loss": 0.6301,
      "step": 457500
    },
    {
      "epoch": 4.81,
      "learning_rate": 2.5952198431117225e-05,
      "loss": 0.6348,
      "step": 458000
    },
    {
      "epoch": 4.81,
      "learning_rate": 2.592594537263591e-05,
      "loss": 0.6338,
      "step": 458500
    },
    {
      "epoch": 4.82,
      "learning_rate": 2.58996923141546e-05,
      "loss": 0.6341,
      "step": 459000
    },
    {
      "epoch": 4.83,
      "learning_rate": 2.587343925567329e-05,
      "loss": 0.6278,
      "step": 459500
    },
    {
      "epoch": 4.83,
      "learning_rate": 2.5847186197191974e-05,
      "loss": 0.6324,
      "step": 460000
    },
    {
      "epoch": 4.84,
      "learning_rate": 2.5820933138710663e-05,
      "loss": 0.625,
      "step": 460500
    },
    {
      "epoch": 4.84,
      "learning_rate": 2.579468008022935e-05,
      "loss": 0.6315,
      "step": 461000
    },
    {
      "epoch": 4.85,
      "learning_rate": 2.5768427021748038e-05,
      "loss": 0.6264,
      "step": 461500
    },
    {
      "epoch": 4.85,
      "learning_rate": 2.574217396326672e-05,
      "loss": 0.6354,
      "step": 462000
    },
    {
      "epoch": 4.86,
      "learning_rate": 2.5715920904785406e-05,
      "loss": 0.6296,
      "step": 462500
    },
    {
      "epoch": 4.86,
      "learning_rate": 2.5689667846304094e-05,
      "loss": 0.6313,
      "step": 463000
    },
    {
      "epoch": 4.87,
      "learning_rate": 2.566341478782278e-05,
      "loss": 0.6288,
      "step": 463500
    },
    {
      "epoch": 4.87,
      "learning_rate": 2.563716172934147e-05,
      "loss": 0.6281,
      "step": 464000
    },
    {
      "epoch": 4.88,
      "learning_rate": 2.5610908670860158e-05,
      "loss": 0.634,
      "step": 464500
    },
    {
      "epoch": 4.88,
      "learning_rate": 2.5584655612378843e-05,
      "loss": 0.6314,
      "step": 465000
    },
    {
      "epoch": 4.89,
      "learning_rate": 2.5558402553897532e-05,
      "loss": 0.623,
      "step": 465500
    },
    {
      "epoch": 4.89,
      "learning_rate": 2.5532149495416218e-05,
      "loss": 0.616,
      "step": 466000
    },
    {
      "epoch": 4.9,
      "learning_rate": 2.5505896436934907e-05,
      "loss": 0.6256,
      "step": 466500
    },
    {
      "epoch": 4.9,
      "learning_rate": 2.5479643378453592e-05,
      "loss": 0.6302,
      "step": 467000
    },
    {
      "epoch": 4.91,
      "learning_rate": 2.5453390319972275e-05,
      "loss": 0.6207,
      "step": 467500
    },
    {
      "epoch": 4.91,
      "learning_rate": 2.5427137261490964e-05,
      "loss": 0.6324,
      "step": 468000
    },
    {
      "epoch": 4.92,
      "learning_rate": 2.540088420300965e-05,
      "loss": 0.6311,
      "step": 468500
    },
    {
      "epoch": 4.93,
      "learning_rate": 2.5374631144528338e-05,
      "loss": 0.6295,
      "step": 469000
    },
    {
      "epoch": 4.93,
      "learning_rate": 2.5348378086047027e-05,
      "loss": 0.628,
      "step": 469500
    },
    {
      "epoch": 4.94,
      "learning_rate": 2.5322125027565713e-05,
      "loss": 0.6228,
      "step": 470000
    },
    {
      "epoch": 4.94,
      "learning_rate": 2.52958719690844e-05,
      "loss": 0.6277,
      "step": 470500
    },
    {
      "epoch": 4.95,
      "learning_rate": 2.5269618910603087e-05,
      "loss": 0.6248,
      "step": 471000
    },
    {
      "epoch": 4.95,
      "learning_rate": 2.5243365852121776e-05,
      "loss": 0.6208,
      "step": 471500
    },
    {
      "epoch": 4.96,
      "learning_rate": 2.521711279364046e-05,
      "loss": 0.6286,
      "step": 472000
    },
    {
      "epoch": 4.96,
      "learning_rate": 2.5190859735159144e-05,
      "loss": 0.6187,
      "step": 472500
    },
    {
      "epoch": 4.97,
      "learning_rate": 2.5164606676677833e-05,
      "loss": 0.6207,
      "step": 473000
    },
    {
      "epoch": 4.97,
      "learning_rate": 2.5138353618196518e-05,
      "loss": 0.6256,
      "step": 473500
    },
    {
      "epoch": 4.98,
      "learning_rate": 2.5112100559715207e-05,
      "loss": 0.6225,
      "step": 474000
    },
    {
      "epoch": 4.98,
      "learning_rate": 2.5085847501233896e-05,
      "loss": 0.6236,
      "step": 474500
    },
    {
      "epoch": 4.99,
      "learning_rate": 2.5059594442752582e-05,
      "loss": 0.6273,
      "step": 475000
    },
    {
      "epoch": 4.99,
      "learning_rate": 2.503334138427127e-05,
      "loss": 0.623,
      "step": 475500
    },
    {
      "epoch": 5.0,
      "learning_rate": 2.5007088325789956e-05,
      "loss": 0.6302,
      "step": 476000
    },
    {
      "epoch": 5.0,
      "learning_rate": 2.4980835267308642e-05,
      "loss": 0.6231,
      "step": 476500
    },
    {
      "epoch": 5.01,
      "learning_rate": 2.4954582208827327e-05,
      "loss": 0.6227,
      "step": 477000
    },
    {
      "epoch": 5.01,
      "learning_rate": 2.4928329150346016e-05,
      "loss": 0.6199,
      "step": 477500
    },
    {
      "epoch": 5.02,
      "learning_rate": 2.4902076091864705e-05,
      "loss": 0.6207,
      "step": 478000
    },
    {
      "epoch": 5.02,
      "learning_rate": 2.487582303338339e-05,
      "loss": 0.6207,
      "step": 478500
    },
    {
      "epoch": 5.03,
      "learning_rate": 2.4849569974902076e-05,
      "loss": 0.6177,
      "step": 479000
    },
    {
      "epoch": 5.04,
      "learning_rate": 2.4823316916420762e-05,
      "loss": 0.6139,
      "step": 479500
    },
    {
      "epoch": 5.04,
      "learning_rate": 2.479706385793945e-05,
      "loss": 0.62,
      "step": 480000
    },
    {
      "epoch": 5.05,
      "learning_rate": 2.477081079945814e-05,
      "loss": 0.6145,
      "step": 480500
    },
    {
      "epoch": 5.05,
      "learning_rate": 2.4744557740976825e-05,
      "loss": 0.6221,
      "step": 481000
    },
    {
      "epoch": 5.06,
      "learning_rate": 2.471830468249551e-05,
      "loss": 0.6118,
      "step": 481500
    },
    {
      "epoch": 5.06,
      "learning_rate": 2.4692051624014196e-05,
      "loss": 0.6124,
      "step": 482000
    },
    {
      "epoch": 5.07,
      "learning_rate": 2.4665798565532885e-05,
      "loss": 0.6167,
      "step": 482500
    },
    {
      "epoch": 5.07,
      "learning_rate": 2.4639545507051574e-05,
      "loss": 0.6165,
      "step": 483000
    },
    {
      "epoch": 5.08,
      "learning_rate": 2.461329244857026e-05,
      "loss": 0.6159,
      "step": 483500
    },
    {
      "epoch": 5.08,
      "learning_rate": 2.458703939008895e-05,
      "loss": 0.6134,
      "step": 484000
    },
    {
      "epoch": 5.09,
      "learning_rate": 2.456078633160763e-05,
      "loss": 0.6189,
      "step": 484500
    },
    {
      "epoch": 5.09,
      "learning_rate": 2.453453327312632e-05,
      "loss": 0.6098,
      "step": 485000
    },
    {
      "epoch": 5.1,
      "learning_rate": 2.450828021464501e-05,
      "loss": 0.625,
      "step": 485500
    },
    {
      "epoch": 5.1,
      "learning_rate": 2.4482027156163694e-05,
      "loss": 0.6163,
      "step": 486000
    },
    {
      "epoch": 5.11,
      "learning_rate": 2.4455774097682383e-05,
      "loss": 0.6227,
      "step": 486500
    },
    {
      "epoch": 5.11,
      "learning_rate": 2.4429521039201066e-05,
      "loss": 0.6145,
      "step": 487000
    },
    {
      "epoch": 5.12,
      "learning_rate": 2.4403267980719754e-05,
      "loss": 0.613,
      "step": 487500
    },
    {
      "epoch": 5.12,
      "learning_rate": 2.4377014922238443e-05,
      "loss": 0.6147,
      "step": 488000
    },
    {
      "epoch": 5.13,
      "learning_rate": 2.435076186375713e-05,
      "loss": 0.6199,
      "step": 488500
    },
    {
      "epoch": 5.14,
      "learning_rate": 2.4324508805275818e-05,
      "loss": 0.6228,
      "step": 489000
    },
    {
      "epoch": 5.14,
      "learning_rate": 2.42982557467945e-05,
      "loss": 0.6127,
      "step": 489500
    },
    {
      "epoch": 5.15,
      "learning_rate": 2.427200268831319e-05,
      "loss": 0.6182,
      "step": 490000
    },
    {
      "epoch": 5.15,
      "learning_rate": 2.4245749629831878e-05,
      "loss": 0.6126,
      "step": 490500
    },
    {
      "epoch": 5.16,
      "learning_rate": 2.4219496571350564e-05,
      "loss": 0.609,
      "step": 491000
    },
    {
      "epoch": 5.16,
      "learning_rate": 2.4193243512869252e-05,
      "loss": 0.6139,
      "step": 491500
    },
    {
      "epoch": 5.17,
      "learning_rate": 2.4166990454387935e-05,
      "loss": 0.6128,
      "step": 492000
    },
    {
      "epoch": 5.17,
      "learning_rate": 2.4140737395906624e-05,
      "loss": 0.6135,
      "step": 492500
    },
    {
      "epoch": 5.18,
      "learning_rate": 2.4114484337425313e-05,
      "loss": 0.6101,
      "step": 493000
    },
    {
      "epoch": 5.18,
      "learning_rate": 2.4088231278943998e-05,
      "loss": 0.6063,
      "step": 493500
    },
    {
      "epoch": 5.19,
      "learning_rate": 2.4061978220462687e-05,
      "loss": 0.613,
      "step": 494000
    },
    {
      "epoch": 5.19,
      "learning_rate": 2.4035725161981373e-05,
      "loss": 0.6089,
      "step": 494500
    },
    {
      "epoch": 5.2,
      "learning_rate": 2.4009472103500058e-05,
      "loss": 0.6002,
      "step": 495000
    },
    {
      "epoch": 5.2,
      "learning_rate": 2.3983219045018747e-05,
      "loss": 0.6094,
      "step": 495500
    },
    {
      "epoch": 5.21,
      "learning_rate": 2.3956965986537433e-05,
      "loss": 0.613,
      "step": 496000
    },
    {
      "epoch": 5.21,
      "learning_rate": 2.393071292805612e-05,
      "loss": 0.6182,
      "step": 496500
    },
    {
      "epoch": 5.22,
      "learning_rate": 2.3904459869574807e-05,
      "loss": 0.6022,
      "step": 497000
    },
    {
      "epoch": 5.22,
      "learning_rate": 2.3878206811093493e-05,
      "loss": 0.6073,
      "step": 497500
    },
    {
      "epoch": 5.23,
      "learning_rate": 2.385195375261218e-05,
      "loss": 0.6157,
      "step": 498000
    },
    {
      "epoch": 5.23,
      "learning_rate": 2.3825700694130867e-05,
      "loss": 0.6198,
      "step": 498500
    },
    {
      "epoch": 5.24,
      "learning_rate": 2.3799447635649556e-05,
      "loss": 0.6087,
      "step": 499000
    },
    {
      "epoch": 5.25,
      "learning_rate": 2.3773194577168242e-05,
      "loss": 0.6051,
      "step": 499500
    },
    {
      "epoch": 5.25,
      "learning_rate": 2.3746941518686927e-05,
      "loss": 0.6091,
      "step": 500000
    },
    {
      "epoch": 5.26,
      "learning_rate": 2.3720688460205616e-05,
      "loss": 0.612,
      "step": 500500
    },
    {
      "epoch": 5.26,
      "learning_rate": 2.3694435401724302e-05,
      "loss": 0.5992,
      "step": 501000
    },
    {
      "epoch": 5.27,
      "learning_rate": 2.366818234324299e-05,
      "loss": 0.6154,
      "step": 501500
    },
    {
      "epoch": 5.27,
      "learning_rate": 2.3641929284761676e-05,
      "loss": 0.6098,
      "step": 502000
    },
    {
      "epoch": 5.28,
      "learning_rate": 2.3615676226280362e-05,
      "loss": 0.6041,
      "step": 502500
    },
    {
      "epoch": 5.28,
      "learning_rate": 2.3589423167799047e-05,
      "loss": 0.6105,
      "step": 503000
    },
    {
      "epoch": 5.29,
      "learning_rate": 2.3563170109317736e-05,
      "loss": 0.6058,
      "step": 503500
    },
    {
      "epoch": 5.29,
      "learning_rate": 2.3536917050836425e-05,
      "loss": 0.613,
      "step": 504000
    },
    {
      "epoch": 5.3,
      "learning_rate": 2.351066399235511e-05,
      "loss": 0.6104,
      "step": 504500
    },
    {
      "epoch": 5.3,
      "learning_rate": 2.3484410933873796e-05,
      "loss": 0.6125,
      "step": 505000
    },
    {
      "epoch": 5.31,
      "learning_rate": 2.3458157875392482e-05,
      "loss": 0.6108,
      "step": 505500
    },
    {
      "epoch": 5.31,
      "learning_rate": 2.343190481691117e-05,
      "loss": 0.6038,
      "step": 506000
    },
    {
      "epoch": 5.32,
      "learning_rate": 2.340565175842986e-05,
      "loss": 0.6043,
      "step": 506500
    },
    {
      "epoch": 5.32,
      "learning_rate": 2.3379398699948545e-05,
      "loss": 0.6044,
      "step": 507000
    },
    {
      "epoch": 5.33,
      "learning_rate": 2.3353145641467234e-05,
      "loss": 0.6073,
      "step": 507500
    },
    {
      "epoch": 5.33,
      "learning_rate": 2.3326892582985916e-05,
      "loss": 0.6085,
      "step": 508000
    },
    {
      "epoch": 5.34,
      "learning_rate": 2.3300639524504605e-05,
      "loss": 0.6142,
      "step": 508500
    },
    {
      "epoch": 5.35,
      "learning_rate": 2.3274386466023294e-05,
      "loss": 0.611,
      "step": 509000
    },
    {
      "epoch": 5.35,
      "learning_rate": 2.324813340754198e-05,
      "loss": 0.6051,
      "step": 509500
    },
    {
      "epoch": 5.36,
      "learning_rate": 2.322188034906067e-05,
      "loss": 0.6116,
      "step": 510000
    },
    {
      "epoch": 5.36,
      "learning_rate": 2.319562729057935e-05,
      "loss": 0.6037,
      "step": 510500
    },
    {
      "epoch": 5.37,
      "learning_rate": 2.316937423209804e-05,
      "loss": 0.6066,
      "step": 511000
    },
    {
      "epoch": 5.37,
      "learning_rate": 2.314312117361673e-05,
      "loss": 0.6027,
      "step": 511500
    },
    {
      "epoch": 5.38,
      "learning_rate": 2.3116868115135414e-05,
      "loss": 0.6097,
      "step": 512000
    },
    {
      "epoch": 5.38,
      "learning_rate": 2.3090615056654103e-05,
      "loss": 0.5982,
      "step": 512500
    },
    {
      "epoch": 5.39,
      "learning_rate": 2.3064361998172786e-05,
      "loss": 0.5945,
      "step": 513000
    },
    {
      "epoch": 5.39,
      "learning_rate": 2.3038108939691475e-05,
      "loss": 0.6033,
      "step": 513500
    },
    {
      "epoch": 5.4,
      "learning_rate": 2.3011855881210163e-05,
      "loss": 0.6047,
      "step": 514000
    },
    {
      "epoch": 5.4,
      "learning_rate": 2.298560282272885e-05,
      "loss": 0.6014,
      "step": 514500
    },
    {
      "epoch": 5.41,
      "learning_rate": 2.2959349764247538e-05,
      "loss": 0.6112,
      "step": 515000
    },
    {
      "epoch": 5.41,
      "learning_rate": 2.293309670576622e-05,
      "loss": 0.6117,
      "step": 515500
    },
    {
      "epoch": 5.42,
      "learning_rate": 2.290684364728491e-05,
      "loss": 0.6049,
      "step": 516000
    },
    {
      "epoch": 5.42,
      "learning_rate": 2.2880590588803598e-05,
      "loss": 0.6018,
      "step": 516500
    },
    {
      "epoch": 5.43,
      "learning_rate": 2.2854337530322284e-05,
      "loss": 0.6095,
      "step": 517000
    },
    {
      "epoch": 5.43,
      "learning_rate": 2.2828084471840973e-05,
      "loss": 0.6071,
      "step": 517500
    },
    {
      "epoch": 5.44,
      "learning_rate": 2.2801831413359655e-05,
      "loss": 0.6076,
      "step": 518000
    },
    {
      "epoch": 5.44,
      "learning_rate": 2.2775578354878344e-05,
      "loss": 0.6061,
      "step": 518500
    },
    {
      "epoch": 5.45,
      "learning_rate": 2.2749325296397033e-05,
      "loss": 0.6047,
      "step": 519000
    },
    {
      "epoch": 5.46,
      "learning_rate": 2.2723072237915718e-05,
      "loss": 0.5987,
      "step": 519500
    },
    {
      "epoch": 5.46,
      "learning_rate": 2.2696819179434407e-05,
      "loss": 0.6073,
      "step": 520000
    },
    {
      "epoch": 5.47,
      "learning_rate": 2.2670566120953093e-05,
      "loss": 0.6009,
      "step": 520500
    },
    {
      "epoch": 5.47,
      "learning_rate": 2.2644313062471778e-05,
      "loss": 0.5998,
      "step": 521000
    },
    {
      "epoch": 5.48,
      "learning_rate": 2.2618060003990467e-05,
      "loss": 0.6087,
      "step": 521500
    },
    {
      "epoch": 5.48,
      "learning_rate": 2.2591806945509153e-05,
      "loss": 0.6009,
      "step": 522000
    },
    {
      "epoch": 5.49,
      "learning_rate": 2.256555388702784e-05,
      "loss": 0.6043,
      "step": 522500
    },
    {
      "epoch": 5.49,
      "learning_rate": 2.2539300828546527e-05,
      "loss": 0.6054,
      "step": 523000
    },
    {
      "epoch": 5.5,
      "learning_rate": 2.2513047770065213e-05,
      "loss": 0.6054,
      "step": 523500
    },
    {
      "epoch": 5.5,
      "learning_rate": 2.2486794711583902e-05,
      "loss": 0.6111,
      "step": 524000
    },
    {
      "epoch": 5.51,
      "learning_rate": 2.2460541653102587e-05,
      "loss": 0.601,
      "step": 524500
    },
    {
      "epoch": 5.51,
      "learning_rate": 2.2434288594621276e-05,
      "loss": 0.5907,
      "step": 525000
    },
    {
      "epoch": 5.52,
      "learning_rate": 2.2408035536139962e-05,
      "loss": 0.6015,
      "step": 525500
    },
    {
      "epoch": 5.52,
      "learning_rate": 2.2381782477658647e-05,
      "loss": 0.6027,
      "step": 526000
    },
    {
      "epoch": 5.53,
      "learning_rate": 2.2355529419177333e-05,
      "loss": 0.6055,
      "step": 526500
    },
    {
      "epoch": 5.53,
      "learning_rate": 2.2329276360696022e-05,
      "loss": 0.5943,
      "step": 527000
    },
    {
      "epoch": 5.54,
      "learning_rate": 2.230302330221471e-05,
      "loss": 0.6091,
      "step": 527500
    },
    {
      "epoch": 5.54,
      "learning_rate": 2.2276770243733396e-05,
      "loss": 0.6024,
      "step": 528000
    },
    {
      "epoch": 5.55,
      "learning_rate": 2.2250517185252082e-05,
      "loss": 0.5998,
      "step": 528500
    },
    {
      "epoch": 5.56,
      "learning_rate": 2.2224264126770767e-05,
      "loss": 0.6042,
      "step": 529000
    },
    {
      "epoch": 5.56,
      "learning_rate": 2.2198011068289456e-05,
      "loss": 0.6039,
      "step": 529500
    },
    {
      "epoch": 5.57,
      "learning_rate": 2.2171758009808145e-05,
      "loss": 0.5973,
      "step": 530000
    },
    {
      "epoch": 5.57,
      "learning_rate": 2.214550495132683e-05,
      "loss": 0.6026,
      "step": 530500
    },
    {
      "epoch": 5.58,
      "learning_rate": 2.211925189284552e-05,
      "loss": 0.6001,
      "step": 531000
    },
    {
      "epoch": 5.58,
      "learning_rate": 2.2092998834364202e-05,
      "loss": 0.6026,
      "step": 531500
    },
    {
      "epoch": 5.59,
      "learning_rate": 2.206674577588289e-05,
      "loss": 0.5996,
      "step": 532000
    },
    {
      "epoch": 5.59,
      "learning_rate": 2.204049271740158e-05,
      "loss": 0.5929,
      "step": 532500
    },
    {
      "epoch": 5.6,
      "learning_rate": 2.2014239658920265e-05,
      "loss": 0.592,
      "step": 533000
    },
    {
      "epoch": 5.6,
      "learning_rate": 2.1987986600438954e-05,
      "loss": 0.5968,
      "step": 533500
    },
    {
      "epoch": 5.61,
      "learning_rate": 2.1961733541957637e-05,
      "loss": 0.5972,
      "step": 534000
    },
    {
      "epoch": 5.61,
      "learning_rate": 2.1935480483476326e-05,
      "loss": 0.5921,
      "step": 534500
    },
    {
      "epoch": 5.62,
      "learning_rate": 2.1909227424995014e-05,
      "loss": 0.6023,
      "step": 535000
    },
    {
      "epoch": 5.62,
      "learning_rate": 2.18829743665137e-05,
      "loss": 0.595,
      "step": 535500
    },
    {
      "epoch": 5.63,
      "learning_rate": 2.185672130803239e-05,
      "loss": 0.6039,
      "step": 536000
    },
    {
      "epoch": 5.63,
      "learning_rate": 2.183046824955107e-05,
      "loss": 0.5979,
      "step": 536500
    },
    {
      "epoch": 5.64,
      "learning_rate": 2.180421519106976e-05,
      "loss": 0.5921,
      "step": 537000
    },
    {
      "epoch": 5.64,
      "learning_rate": 2.177796213258845e-05,
      "loss": 0.5949,
      "step": 537500
    },
    {
      "epoch": 5.65,
      "learning_rate": 2.1751709074107135e-05,
      "loss": 0.5969,
      "step": 538000
    },
    {
      "epoch": 5.65,
      "learning_rate": 2.1725456015625824e-05,
      "loss": 0.5971,
      "step": 538500
    },
    {
      "epoch": 5.66,
      "learning_rate": 2.1699202957144506e-05,
      "loss": 0.5932,
      "step": 539000
    },
    {
      "epoch": 5.67,
      "learning_rate": 2.1672949898663195e-05,
      "loss": 0.598,
      "step": 539500
    },
    {
      "epoch": 5.67,
      "learning_rate": 2.1646696840181884e-05,
      "loss": 0.596,
      "step": 540000
    },
    {
      "epoch": 5.68,
      "learning_rate": 2.162044378170057e-05,
      "loss": 0.5954,
      "step": 540500
    },
    {
      "epoch": 5.68,
      "learning_rate": 2.1594190723219258e-05,
      "loss": 0.6061,
      "step": 541000
    },
    {
      "epoch": 5.69,
      "learning_rate": 2.156793766473794e-05,
      "loss": 0.5913,
      "step": 541500
    },
    {
      "epoch": 5.69,
      "learning_rate": 2.154168460625663e-05,
      "loss": 0.5879,
      "step": 542000
    },
    {
      "epoch": 5.7,
      "learning_rate": 2.1515431547775318e-05,
      "loss": 0.593,
      "step": 542500
    },
    {
      "epoch": 5.7,
      "learning_rate": 2.1489178489294004e-05,
      "loss": 0.5928,
      "step": 543000
    },
    {
      "epoch": 5.71,
      "learning_rate": 2.1462925430812693e-05,
      "loss": 0.5948,
      "step": 543500
    },
    {
      "epoch": 5.71,
      "learning_rate": 2.1436672372331378e-05,
      "loss": 0.5919,
      "step": 544000
    },
    {
      "epoch": 5.72,
      "learning_rate": 2.1410419313850064e-05,
      "loss": 0.5997,
      "step": 544500
    },
    {
      "epoch": 5.72,
      "learning_rate": 2.1384166255368753e-05,
      "loss": 0.5921,
      "step": 545000
    },
    {
      "epoch": 5.73,
      "learning_rate": 2.1357913196887438e-05,
      "loss": 0.5953,
      "step": 545500
    },
    {
      "epoch": 5.73,
      "learning_rate": 2.1331660138406127e-05,
      "loss": 0.5877,
      "step": 546000
    },
    {
      "epoch": 5.74,
      "learning_rate": 2.1305407079924813e-05,
      "loss": 0.5993,
      "step": 546500
    },
    {
      "epoch": 5.74,
      "learning_rate": 2.1279154021443498e-05,
      "loss": 0.594,
      "step": 547000
    },
    {
      "epoch": 5.75,
      "learning_rate": 2.1252900962962187e-05,
      "loss": 0.5969,
      "step": 547500
    },
    {
      "epoch": 5.75,
      "learning_rate": 2.1226647904480873e-05,
      "loss": 0.59,
      "step": 548000
    },
    {
      "epoch": 5.76,
      "learning_rate": 2.1200394845999562e-05,
      "loss": 0.5928,
      "step": 548500
    },
    {
      "epoch": 5.77,
      "learning_rate": 2.1174141787518247e-05,
      "loss": 0.5868,
      "step": 549000
    },
    {
      "epoch": 5.77,
      "learning_rate": 2.1147888729036933e-05,
      "loss": 0.5987,
      "step": 549500
    },
    {
      "epoch": 5.78,
      "learning_rate": 2.1121635670555622e-05,
      "loss": 0.5941,
      "step": 550000
    },
    {
      "epoch": 5.78,
      "learning_rate": 2.1095382612074307e-05,
      "loss": 0.5861,
      "step": 550500
    },
    {
      "epoch": 5.79,
      "learning_rate": 2.1069129553592996e-05,
      "loss": 0.6003,
      "step": 551000
    },
    {
      "epoch": 5.79,
      "learning_rate": 2.1042876495111682e-05,
      "loss": 0.5871,
      "step": 551500
    },
    {
      "epoch": 5.8,
      "learning_rate": 2.1016623436630367e-05,
      "loss": 0.5982,
      "step": 552000
    },
    {
      "epoch": 5.8,
      "learning_rate": 2.0990370378149053e-05,
      "loss": 0.59,
      "step": 552500
    },
    {
      "epoch": 5.81,
      "learning_rate": 2.0964117319667742e-05,
      "loss": 0.5941,
      "step": 553000
    },
    {
      "epoch": 5.81,
      "learning_rate": 2.093786426118643e-05,
      "loss": 0.586,
      "step": 553500
    },
    {
      "epoch": 5.82,
      "learning_rate": 2.0911611202705116e-05,
      "loss": 0.5847,
      "step": 554000
    },
    {
      "epoch": 5.82,
      "learning_rate": 2.0885358144223805e-05,
      "loss": 0.6015,
      "step": 554500
    },
    {
      "epoch": 5.83,
      "learning_rate": 2.0859105085742488e-05,
      "loss": 0.5918,
      "step": 555000
    },
    {
      "epoch": 5.83,
      "learning_rate": 2.0832852027261176e-05,
      "loss": 0.5855,
      "step": 555500
    },
    {
      "epoch": 5.84,
      "learning_rate": 2.0806598968779865e-05,
      "loss": 0.5941,
      "step": 556000
    },
    {
      "epoch": 5.84,
      "learning_rate": 2.078034591029855e-05,
      "loss": 0.5978,
      "step": 556500
    },
    {
      "epoch": 5.85,
      "learning_rate": 2.075409285181724e-05,
      "loss": 0.5857,
      "step": 557000
    },
    {
      "epoch": 5.85,
      "learning_rate": 2.0727839793335922e-05,
      "loss": 0.5845,
      "step": 557500
    },
    {
      "epoch": 5.86,
      "learning_rate": 2.070158673485461e-05,
      "loss": 0.5899,
      "step": 558000
    },
    {
      "epoch": 5.86,
      "learning_rate": 2.06753336763733e-05,
      "loss": 0.5997,
      "step": 558500
    },
    {
      "epoch": 5.87,
      "learning_rate": 2.0649080617891986e-05,
      "loss": 0.5925,
      "step": 559000
    },
    {
      "epoch": 5.88,
      "learning_rate": 2.0622827559410674e-05,
      "loss": 0.5887,
      "step": 559500
    },
    {
      "epoch": 5.88,
      "learning_rate": 2.0596574500929357e-05,
      "loss": 0.5925,
      "step": 560000
    },
    {
      "epoch": 5.89,
      "learning_rate": 2.0570321442448046e-05,
      "loss": 0.5804,
      "step": 560500
    },
    {
      "epoch": 5.89,
      "learning_rate": 2.0544068383966735e-05,
      "loss": 0.5876,
      "step": 561000
    },
    {
      "epoch": 5.9,
      "learning_rate": 2.051781532548542e-05,
      "loss": 0.5942,
      "step": 561500
    },
    {
      "epoch": 5.9,
      "learning_rate": 2.049156226700411e-05,
      "loss": 0.5883,
      "step": 562000
    },
    {
      "epoch": 5.91,
      "learning_rate": 2.046530920852279e-05,
      "loss": 0.5854,
      "step": 562500
    },
    {
      "epoch": 5.91,
      "learning_rate": 2.043905615004148e-05,
      "loss": 0.5917,
      "step": 563000
    },
    {
      "epoch": 5.92,
      "learning_rate": 2.041280309156017e-05,
      "loss": 0.5896,
      "step": 563500
    },
    {
      "epoch": 5.92,
      "learning_rate": 2.0386550033078855e-05,
      "loss": 0.5887,
      "step": 564000
    },
    {
      "epoch": 5.93,
      "learning_rate": 2.0360296974597544e-05,
      "loss": 0.582,
      "step": 564500
    },
    {
      "epoch": 5.93,
      "learning_rate": 2.0334043916116226e-05,
      "loss": 0.5926,
      "step": 565000
    },
    {
      "epoch": 5.94,
      "learning_rate": 2.0307790857634915e-05,
      "loss": 0.5832,
      "step": 565500
    },
    {
      "epoch": 5.94,
      "learning_rate": 2.0281537799153604e-05,
      "loss": 0.5927,
      "step": 566000
    },
    {
      "epoch": 5.95,
      "learning_rate": 2.025528474067229e-05,
      "loss": 0.5837,
      "step": 566500
    },
    {
      "epoch": 5.95,
      "learning_rate": 2.0229031682190978e-05,
      "loss": 0.5905,
      "step": 567000
    },
    {
      "epoch": 5.96,
      "learning_rate": 2.0202778623709664e-05,
      "loss": 0.5856,
      "step": 567500
    },
    {
      "epoch": 5.96,
      "learning_rate": 2.017652556522835e-05,
      "loss": 0.5878,
      "step": 568000
    },
    {
      "epoch": 5.97,
      "learning_rate": 2.0150272506747038e-05,
      "loss": 0.5868,
      "step": 568500
    },
    {
      "epoch": 5.98,
      "learning_rate": 2.0124019448265724e-05,
      "loss": 0.5859,
      "step": 569000
    },
    {
      "epoch": 5.98,
      "learning_rate": 2.0097766389784413e-05,
      "loss": 0.5808,
      "step": 569500
    },
    {
      "epoch": 5.99,
      "learning_rate": 2.0071513331303098e-05,
      "loss": 0.5896,
      "step": 570000
    },
    {
      "epoch": 5.99,
      "learning_rate": 2.0045260272821784e-05,
      "loss": 0.5912,
      "step": 570500
    },
    {
      "epoch": 6.0,
      "learning_rate": 2.0019007214340473e-05,
      "loss": 0.5887,
      "step": 571000
    },
    {
      "epoch": 6.0,
      "learning_rate": 1.9992754155859158e-05,
      "loss": 0.5889,
      "step": 571500
    },
    {
      "epoch": 6.01,
      "learning_rate": 1.9966501097377847e-05,
      "loss": 0.5738,
      "step": 572000
    },
    {
      "epoch": 6.01,
      "learning_rate": 1.9940248038896533e-05,
      "loss": 0.584,
      "step": 572500
    },
    {
      "epoch": 6.02,
      "learning_rate": 1.991399498041522e-05,
      "loss": 0.5789,
      "step": 573000
    },
    {
      "epoch": 6.02,
      "learning_rate": 1.9887741921933907e-05,
      "loss": 0.5872,
      "step": 573500
    },
    {
      "epoch": 6.03,
      "learning_rate": 1.9861488863452593e-05,
      "loss": 0.5769,
      "step": 574000
    },
    {
      "epoch": 6.03,
      "learning_rate": 1.9835235804971282e-05,
      "loss": 0.58,
      "step": 574500
    },
    {
      "epoch": 6.04,
      "learning_rate": 1.9808982746489967e-05,
      "loss": 0.5818,
      "step": 575000
    },
    {
      "epoch": 6.04,
      "learning_rate": 1.9782729688008653e-05,
      "loss": 0.5818,
      "step": 575500
    },
    {
      "epoch": 6.05,
      "learning_rate": 1.975647662952734e-05,
      "loss": 0.5844,
      "step": 576000
    },
    {
      "epoch": 6.05,
      "learning_rate": 1.9730223571046027e-05,
      "loss": 0.5801,
      "step": 576500
    },
    {
      "epoch": 6.06,
      "learning_rate": 1.9703970512564716e-05,
      "loss": 0.577,
      "step": 577000
    },
    {
      "epoch": 6.06,
      "learning_rate": 1.9677717454083402e-05,
      "loss": 0.5756,
      "step": 577500
    },
    {
      "epoch": 6.07,
      "learning_rate": 1.965146439560209e-05,
      "loss": 0.5783,
      "step": 578000
    },
    {
      "epoch": 6.07,
      "learning_rate": 1.9625211337120773e-05,
      "loss": 0.5757,
      "step": 578500
    },
    {
      "epoch": 6.08,
      "learning_rate": 1.9598958278639462e-05,
      "loss": 0.5824,
      "step": 579000
    },
    {
      "epoch": 6.09,
      "learning_rate": 1.957270522015815e-05,
      "loss": 0.5846,
      "step": 579500
    },
    {
      "epoch": 6.09,
      "learning_rate": 1.9546452161676836e-05,
      "loss": 0.5775,
      "step": 580000
    }
  ],
  "max_steps": 952270,
  "num_train_epochs": 10,
  "total_flos": 5.210897936255923e+18,
  "trial_name": null,
  "trial_params": null
}
